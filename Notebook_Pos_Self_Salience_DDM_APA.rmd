---
title             : "Positive bias in perceptual matching may reflect an spontaneous self-referential processing"
shorttitle        : "Positive-bias as the spontaneous self-referential processing"

author: 
  - name          : "Hu Chuan-Peng"
    affiliation   : "1,2"
    corresponding : yes    # Define only one corresponding author
    address       : "Langenbeckstr. 1, Neuroimaging Center, University Medical Center Mainz, 55131 Mainz, Germany"
    email         : "hcp4715@gmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "1"
  - name          : "Jie Sui"
    affiliation   : "1,3"

affiliation:
  - id            : "1"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "2"
    institution   : "Leibniz Institute for Resilience Research, 55131 Mainz, Germany"
  - id            : "3"
    institution   : "University of Aberdeen, Aberdeen, Scotland"

authornote: |
  Hu Chuan-Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, School of Psychology, University of Aberdeen, Aberdeen, Scotland.

  Authors contriubtion: HCP, JS, & KP design the study, HCP collected the data, HCP analyzed the data and drafted the manuscript. KP & JS supported this project.

abstract: |
  To navigate in a complex social world, individual has learnt to prioritize valuable information. Previous studies suggested the moral related stimuli was prioritized (Anderson, Siegel, et al., 2011, Science; Gantman & Van Bavel, 2014, Cognition). Using social associative learning paradigm, we found that when geometric shapes, without soical meaning, were associated with different moral valence (morally good, neutral, or bad), the shapes that associated with positive moral valence were prioritized in moral matching task. This patterns of results were robust across different procedures. Further, we tested whether this positive effect was modulated by self-relevance by manipulating the self-referential explicitly and found that the positive bias showed a large effect when positive valued stimuli were related to the self. This effect exist also when the self related information were presented as a task-irrelevant information. We also tested the specificity of the positive valence and found that this effect was not limited to moral domain. Interestingly, the better performance in reaction time is not correpsonding to self-rated psychological distance between self and a morally good-person, but with distance between self and morall bad-person. These results may suggest that our participants (College students in two different cities in China) have a positive moral self bias in perceptual processing, which drive the facilitated processing of morally good stimuli because of the spontaneous self-referential processing, and this trendency is not correlated with explicit rating of moral self.
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self, positive bias, morality"
wordcount         : "X"

bibliography      : 
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
figsintext        : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

---

```{r setup, include = FALSE}
#rm(list = ls())
if (.Platform$OS.type == 'windows') {
  Sys.setlocale(category = 'LC_ALL','English_United States.1250')
} else {
  Sys.setlocale(category = 'LC_ALL','en_US.UTF-8')
}

#Sys.setlocale("LC_ALL", "English")  # set local encoding to English
Sys.setenv(LANG = "en") # set the feedback language to English
options(scipen = 999)   # force R to output in decimal instead of scientific notion
options(digits=5)       # limit the number of reporting

pkgTest <- function(x)
{
        if (!require(x,character.only = TRUE))
        {
                install.packages(x, dep = TRUE)
                if(!require(x,character.only = TRUE)) stop("Package not found")
        }
}

pkgNeeded <- (c("tidyverse", 'metafor',
                "corrplot","readr", 
                'mosaic', 'here',
                'brms'
                ))

lapply(pkgNeeded,pkgTest)
rm('pkgNeeded') # remove the variable 'pkgNeeded';

if(!"qgraph" %in% rownames(installed.packages())) install.packages("qgraph")
if(!"tidybayes" %in% rownames(installed.packages())) install.packages("tidybayes")

# Install devtools package if necessary
if(!"devtools" %in% rownames(installed.packages())) install.packages("devtools")

# Install the stable development verions from GitHub
if(!"papaja" %in% rownames(installed.packages())) devtools::install_github("crsh/papaja")

#windowsFonts(Times=windowsFont("TT Times New Roman")) # explicit mapping to "times"
apatheme = theme_bw()+
        theme(panel.grid.major = element_blank(),
              panel.grid.minor = element_blank(),
              panel.background = element_blank(),
              panel.border = element_blank(),
              text=element_text(family='Times'),
              legend.title=element_blank(),
              legend.text = element_text(size =12),
              #legend.position='top',
              plot.title = element_text(lineheight=.8, face="bold", size = 16),
#              plot.title = element_text(lineheight=.8, face="bold", size = 16, hjust = 0.5),
              axis.text = element_text (size = 14, color = 'black'),
#              axis.text.x = element_text(angle = 45, vjust = 0.5),   # x-axis's label font
              axis.title = element_text (size = 14),
              axis.line.x = element_line(color='black', size = 1),   # increase the size of font
              axis.line.y = element_line(color='black', size = 1),   # increase the size of font
              axis.title.x = element_text(margin=margin(10,0,0,0)),  # increase the sapce betwen title and x axis
              axis.title.y = element_text(margin=margin(0,12,0,0)))  # increase the space between title and y axis

curDir = here::here() #dirname(rstudioapi::getActiveDocumentContext()$path)
figDir = here::here('figures')

# Seed for random number generation
set.seed(42)
options(tinytex.verbose = T) # debug the tex
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)

```

# Introduction
XXXX
In perceptual matching, same is faster than different [Krueger_1978; Farell_1985].
Automatic processing [Spruyt_de_Houwer_2017]

Trisha Van Zandt, Hans Colonius, Robert W. Proctor: A comparison of two response time models applied to perceptual matching

Yakushijin, ReikoJacobs, Robert A (2020), Are People Successful at Learning Sequential Decisions on a Perceptual Matching Task?

Schooler, L. J., Shiffrin, R. M., & Raaijmakers, J. G. W. (2001). A Bayesian model for implicit effects in perceptual identification. Psychological Review, 108(1), 257–272. https://doi.org/10.1037/0033-295X.108.1.257

# Methods
## Participants.
Most experiments (1a ~ 6b, except experiment 3b) reported in the current study were first finished between 2014 to 2016 in Tsinghua University, Beijing, China. Participants of these experiments were recruited in the local community. To increase the sample size so that each experiment has 50 or more valid data [@Simmons_2013_life], we recruited additional participants in Wenzhou University, Wenzhou, China in 2017 for experiment 1a, 1b, 4a, and 4b. Experiment 3b was finished in Wenzhou University in 2017. In the finial meta-analysis, we also included the data from two experiments (experiment 7a, 7b) that were reported in @Hu_2020_GoodSelf (See Table 1 for overview of these experiments). 
All participant received informed consent and compensated for their time. These experiments were approved by the ethic board in the Department of Tsinghua University. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

## Design and Procedure
This series of experiments was set out to test the effect of instantly acquired moral valence on perceptual decision-making. For this purpose, we used the social associative learning paradigm (or self-tagging paradigm)[@Sui_2012_JEPHPP], in which participants first learned the associations between geometric shapes and labels of person with different moral valence (e.g., in first three studies, the triangle, square, and circle and good person, neutral person, and bad person, respectively). The associations of the shapes and label were counterbalanced across participants. After remembered the associations, participants finished a perceptual matching task where they viewed one of the shapes upon the fixation while one of the labels below the fixation and judged whether the shape and the label matched the association they've learned. To get familiar with the task, participants practice the task and only started the experiment When their overall accuracy in the practice session was 60% or higher. 

The experiment 1a, 1b, 1c, 2, and 6a shared a 2 (matchness: matched vs. mismatched) by 3 (moral valence: good vs. neutral vs. bad) within-subject design. The experiment 1a was the first one of the whole series studies and 1b, 1c, and 2 were conducted to exclude the potential confounding factors. More specifically, experiment 1b used different Chinese words as labels to test whether the effect in experiment 1a was caused by the familiarity of the words. Experiment 1c manipulated the moral valence indirectly: participants first learn to associate different moral behaviors with different names of people, after remembered the association, they then performed the perceptual matching task by associating those names with different shapes. Experiment 2 further tested whether the way we presented the stimuli influence the effect of valence, by sequentially presenting labels and shapes. Note that part of participants of experiment 2 were from experiment 1a because we originally planned a cross task comparison. Experiment 6a, which shared the same design as experiment 2, was an EEG experiment which aimed at exploring the neural correlates of the effect. But we will focus on the behavioral results of experiment 6a in the current manuscript.

For experiment 3a, 3b, 6b, 7a, and 7b, we included self-relevance as another within-subject variable in the experimental design. For example, the experiment 3a directly extend the design of experiment 1a into a 2 (matchness: matched vs. mismatched) by 2 (reference: self vs. other) by 3 (moral valence: good vs. neutral vs. bad) within-subject design. Thus, in experiment 3a, there were six conditions (good-self, neutral-self, bad-self, good-other, neutral-other, and bad-other) and six shapes (triangle, square, circle, diamond, pentagon, and trapezoid). Experiment 3b was designed to separate the self-referential trials and other-referential trials and explore the change of task design on the effect we found in previous experiments. That is, participants finished two different blocks: in the self-referential blocks, they only response to good-self, neutral-self, and bad-self, with half of the trials was matched and half was not; for the other-reference blocks, they only responded to good-other, neutral-other, and bad-other. The experiment 6b was an EEG experiment extended from experiment 3a but presented the label and shape sequentially. Because of the relatively high working memory load (six label-shape pairs), experiment 6b were conducted in two days: the first day participants finished perceptual matching task as a practice, and the second day, they finished the task again while the EEG signals were recorded. The experiment 7a and 7b were design to test the cross task robustness of the effect. Given that we found the differences between neutral and bad conditions are negligible, we adopted a simpler experimental design in matching task of experiment 7a and 7b, i.e., with 2 (matchness: matched vs. mismatched) by 2 (reference: self vs. other) [see, @Hu_2020_GoodSelf].

Experiment 4a and 4b were design to test the implicit binding between self/other and moral valence. These two experiments were design to test whether the moral valence and self-referential will interact implicitly. For this purpose, in each experiment, only one variable was used as the explicit task and the other variable was rendered as task-irrlevant variable. In 4a, the explicit task was self-referential matching task, which two labels (self vs. other) and two shapes (circle, square) were used in the learning phase. The moral valence was manipulated by adding those labels within the shape. Participants were instructed to focus on the task and ignore the words in the shape, thus the moral valence was task-irrelevant variable. In 4b, we reversed the role of self-relevance and moral valence in the task: participants learnt three labels (good-person, neutral-person, and bad-person) and three shapes (circle, square, and triangle), and the words for self-relevance, "self" or "other", were presented in the shapes. As in 4a, participants were told to ignore the words inside the shape during the task.

Finally, experiment 5 was design to test the specificity of the moral valence. We extended the moral valence to broader domains. More specifically, besides the moral valence, we added valence from appearance of person (beautiful, neutral, ugly), apperance of a scene (beautiful, neutral, ugly), and emotion (happy, neutral, and sad). Label-shape pairs from different domains were separated into different blocks. 

E-prime 2.0 was used for presenting stimuli and collecting behavioral responses, except that experiment 7a and 7b used Matlab psychtoolbox [@Brainard_1997;@Pelli_1997]. For participants recruited in Tsinghua University, they finished the task individually in a dim-lighted chamber, stimuli were presented on 22-inch CRT monitors and their head were fixed by a chin-rest brace. The distance between participants' eyes and the screen was about 60 cm. The visual angle of geometric shapes was about 3.7º × 3.7º, the fixation cross is of (0.8º × 0.8º of visual angle) at the center of the screen. The words were of 3.6º × 1.6º visual angle. The distance between the center of the shape or the word and the fixation cross was 3.5º of visual angle. For participants recruited in Wenzhou University, they finished the experiment in a group consisted of 3 ~ 12 participants in a dim-lighted testing room. Participants were required to finished the whole experiment independently. Also, they were instructed to start the experiment at the same time, so that the distraction between participants were minimized. The stimuli were presented on 19-inch CRT monitor. The visual angles were not precisely controlled because participants’s chin were not fixed.

In most of these experiments, participant were also asked to fill a battery of questionnaire after they finish the behavioral tasks. All the questionnaire data were open [see, dataset 4 in @Liu_2020_JOPD]. See Table 1 for a summary information about all the experiments reported here. 

```{r 'Table1_exp_info', ehco = FALSE, results = 'asis'}
exp_table <- read.csv('Exp_info_all.csv') %>%
  dplyr::rename(ExpID = 1)
# knitr::kable(exp_table, caption = "Information about all experiments")
papaja::apa_table(
  exp_table
  , caption = "Information about all experiments."
  , note = "DV = dependent variables; Valence = how valence was manipulated; Shape & Label = how shapes & labels were presented."
  , escape = TRUE
)
```

## Data analysis
We reported all the measurements, analyses, and results in all the experiments in the current study. Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200 ms reaction times were excluded from the analysis.

All data were first pre-processed using `r cite_r("r-references.bib")`. We then applied Bayesian hierarchical Drift Diffusion Model to the reaction times (RTs) and accuracy. We used python package HDDM [wiecki_hddm_2013] to fit the model and generated the posterior of each parameter. Then we used the posterior for statistical inferences.


### Valence effect
We synthesized effect size of *d* prime and RT from experiment 1a, 1b, 1c, 2, 5 and 6a for the valence effect. We reported the synthesized the effect across all experiments that tested the valence effect, using Bayesian hierarchical model. 

### Valence-self-relevance interaction
The results from experiment 3a, 3b, 6b, 7a, and 7b. These experiments explicitly included both moral valence and self-reference. 

### Implicit coupling between valence and self-relevance
In the third part, we examined the change of effect size brought by change of design, with a focus on 4a and 4b, which were designed to examine the implicit effect of the interaction between moral valence and self-referential processing. We are interested in one particular question: will self-referential and morally positive valence had a mutual facilitation effect. That is, when moral valence (experiment 4a) or self-referential (experiment 4a) was presented as task-irrelevant stimuli, whether they would facilitate self-referential or valence effect on perceptual decision-making. For experiment 4a, we report the comparisons between different valence conditions under the self-referential task, not the other-referential task; for experiment 4b, we reported the comparison between the self- vs. other-referential conditions for positive moral condition, not for the neutral or negative conditions. Note that the results were also analyzed in a standard repeated measure ANOVAs (see supplementary materials).

### Specificity of the valence effect
In this part, we reported the data from experiment 5, which included positive, neutral, and negative valence from four different domains: morality, aesthetic of person, aesthetic of scene, and emotion. This experiment was design to test whether the positive bias is specific to morality.

### Behavior-Questionnaire correlation

Finally, we explored correlation between results from behavioral results and self-reported measures. 
For the behavioral task part, we derived different indices. First, we used the mean and SD of the RT data from each participants of each condition. We included the RT variation because it has been shown to be meaningful as individual differences [Jensen, 1992; Ouyang et al., 2017]. Second, we used drift diffusion model to estimate four parameters of DDM for each participants. 
The DDM analyses were finished by HDDM, as reported in Hu et al., (2019: https://psyarxiv.com/9fczh/). That is, we used the reponse code approach, matched response were coded as 1 and mismatched responses were coded as 0. To fully explore all parameters, we allow all four parameters of DDM free to vary. We then extracted the estimation of all the four parameters for each participants for the correlation analyses.

For the questinnaire part, we are most interested in the self-rated distance between different person and self-evaluation related questionnaires: self-esteem, moral-self identity, and moral self-image. Other questionnaires (e.g., personality) were not planned to correlated with behavioral data were not included. Note that all data were reported in [@Liu_2020_JOPD].

```{r loadingData,echo=FALSE,results='hide'}
load("AllData.RData")

### expclude the repeated subj from the raw data

# No repeating subj
df1a.v_meta <- df1a.v

# No repeating subj
df1b.v_meta <- df1b.v

# exclude participant from exp 1a
df1c.v_meta <- df1c.v %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))

# exclude participant from exp 1a
df2.v_meta <- df2.v %>% dplyr::filter(Subject > 2000)    

# exclude participants from ex1b, 1c, and 2
df3a.v_meta <- df3a.v %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) 

# No repeating subj
df3b.v_meta <- df3b.v

# No repeating subj
df4a.v_meta <- df4a.v

# exclude participants from ex1b, 1c, and 2
df4b.v_meta <- df4b.v %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   

# exclude participants from ex1b, 1c, and 2
df5.v_meta <- df5.v %>% dplyr::filter(!Subject %in% c(5201))   

# exclude participants from ex1b, 1c, and 2
df6a.v_meta <- df6a.v %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   

# exclude participants from ex1b, 1c, and 2
df6b.v_meta <- df6b_d1.v %>% dplyr::filter(!Subject %in% c(6217))   

# exclude participants from ex1b, 1c, and 2
df7a.v_meta <- df7a_m.v %>% dplyr::filter(!Subject %in% c(7020))   

# No repeating subj
df7b.v_meta <- df7b_m.v

# remove all unnecessary variables
var_list <- c('df1a.v_meta', 'df1b.v_meta', 'df1c.v_meta', 'df2.v_meta', 'df3a.v_meta', 'df3b.v_meta',
              'df4a.v_meta', 'df4b.v_meta', 'df5.v_meta', 'df6a.v_meta', 'df6b.v_meta', 'df7a.v_meta', 'df7b.v_meta',
              'apatheme','exp_table', 'curDir', 'figDir')
rm(list=ls()[! ls() %in% var_list])

df1a.v_meta$ExpID <- 'Exp1a'
df1b.v_meta$ExpID <- 'Exp1b'
df1c.v_meta$ExpID <- 'Exp1c'
df2.v_meta$ExpID <- 'Exp2'
df3a.v_meta$ExpID <- 'Exp3a'
df3b.v_meta$ExpID <- 'Exp3b'
df4a.v_meta$ExpID <- 'Exp4a'
df4b.v_meta$ExpID <- 'Exp4b'
df5.v_meta$ExpID <- 'Exp5'
df6a.v_meta$ExpID <- 'Exp6a'
df6b.v_meta$ExpID <- 'Exp6b'
df7a.v_meta$ExpID <- 'Exp7a'
df7b.v_meta$ExpID <- 'Exp7b'
```

# Results
```{r first meta,echo=FALSE,results='hide'}
### try meta-analysis 1a, 1b, 1c, 2, 5 and 6a
#selected_columns <- c('Subject','Age', 'Sex')

selected_columns <- c('ExpID', 'Site', 'Subject','Age', 'Sex', 'Matchness','Valence', 'RESP', 'ACC','RT')
df_moral <- dplyr::bind_rows(df1a.v_meta[selected_columns],
                             df1b.v_meta[selected_columns],
                             df1c.v_meta[selected_columns],
                             df2.v_meta[selected_columns],
                             df5.v_meta[selected_columns],
                             df6a.v_meta[selected_columns]) %>%
  dplyr::mutate(ExpID_new = paste(ExpID, Site, sep = "_")) %>%
  dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')))

df_moral_subj <- df_moral %>%
  dplyr::group_by(ExpID_new, Site) %>%
  dplyr::summarize(N = n_distinct(Subject),
                   N_trial = length(Subject),
                   Exp_conds = 6,
                   trial_per_cond = round((length(Subject)/6)/N, 0))

df_moral <- df_moral %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0)) %>%
  dplyr::select(ExpID_new, Subject, Valence, Matchness, RESP, ACC, RT, ismatch, saymatch) %>%
  dplyr::mutate(ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# plot the nested structure of the data
with(df_moral, table(Subject, ExpID_new)) %>%
  image(
    col = grey.colors(80, start = 1, end = 0), 
    axes = TRUE, 
    xlab = "Subject", 
    ylab = "ExpID"
  )

# fit a three-level hierarchical model for SDT, didn't specify the prior; effect coding
std_val_m1 <- brms::brm(saymatch ~ 0 + Valence + Valence:ismatch_num + 
                         (0 + Valence + Valence:ismatch_num | ExpID_new) + 
                         (0 + Valence + Valence:ismatch_num  | ExpID_new:Subject),
                       family = bernoulli(link="probit"),
                       data = df_moral,
                       control = list(adapt_delta = .95),
                       cores = parallel::detectCores(),
                       file = here::here("glmmModels/sdt_val_EffectCode_3_level"))

summary(std_val_m1)
stancode(std_val_m1)

plot(hypothesis(std_val_m1,
                "ValenceBad:ismatch_num > ValenceNeutral:ismatch_num"))

plot(hypothesis(std_val_m1,
                "ValenceGood:ismatch_num > ValenceNeutral:ismatch_num"))

# Get the variables in the model
var_name_m1 <- tidybayes::get_variables(std_val_m1)

df_m1_post_sdt_exp <- std_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

pop_mean <- std_val_m1 %>%
  tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood,
                          `b_ValenceBad:ismatch_num`, `b_ValenceNeutral:ismatch_num`, 
                          `b_ValenceGood:ismatch_num`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
tmp <- std_val_m1 %>% 
  tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood,
                          `b_ValenceBad:ismatch_num`, `b_ValenceNeutral:ismatch_num`, 
                          `b_ValenceGood:ismatch_num`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
tmp2 <- merge(tmp, df_m1_post_sdt_exp, by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_plot_sdt <- tmp %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., tmp2) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition), # reverse the order because the plot function auto reverse.
                term = mosaic::derivedFactor("c_bad" = (term == "ValenceBad"),
                                             "c_neutral" = (term == "ValenceNeutral"),
                                             "c_good" = (term == "ValenceGood"),
                                             "dprime_bad" = (term == "ValenceBad:ismatch_num"),
                                             "dprime_neutral" = (term == "ValenceNeutral:ismatch_num"),
                                             "dprime_good" = (term == "ValenceGood:ismatch_num"),
                                             .method ="first", .default = NA),
                term = factor(term, levels = c("c_bad", "c_neutral", "c_good",
                                               "dprime_bad", "dprime_neutral", "dprime_good"))) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_c = c_good - c_bad,                           # calculate the differences between coditions
                diff_GN_c = c_good - c_neutral,
                diff_BN_c = c_bad - c_neutral,
                diff_GB_dprm = dprime_good - dprime_bad,
                diff_GN_dprm = dprime_good - dprime_neutral,
                diff_BN_dprm = dprime_bad - dprime_neutral) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_c,diff_GN_c, diff_BN_c,
               diff_GB_dprm, diff_GN_dprm, diff_BN_dprm) %>%
  tidyr::pivot_longer(cols = diff_GB_c:diff_BN_dprm, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_c','diff_GN_c', 'diff_BN_c',
                                                         'diff_GB_dprm', 'diff_GN_dprm', 'diff_BN_dprm')))

df_m1_plot_sdt %>% 
  dplyr::group_by(condition, term_diff, .chain) %>%
  dplyr::tally()

# plot the posterior of c
df_m1_plot_sdt  %>%
  dplyr::filter(str_detect(term_diff, '_c')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# plot the posterior of dprime
df_m1_plot_sdt %>%
  dplyr::filter(str_detect(term_diff, '_dprm')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# 
#mcmc_plot(std_val_m1, pars = 1:4, type = "dens")

# posterior predictive check
#pp_check(std_val_m1)
#pp_std_val_m1 <- 
#  brms::pp_check(std_val_m1, nsamples = 1e2) + 
#  ggtitle("PPC std_val_m1") +
#  theme_bw (base_size = 10) + 
#  theme(legend.position = "none") +
#  xlim(-0.5, 1.5)

# have a look at a few participants' data
set.seed(123)
random_sub <- sample(unique(df_moral$Subject), 4)
random_sub

df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  dplyr::filter(Subject %in% random_sub) %>%
  dplyr::mutate(cond = paste(Matchness, Valence, sep = "_"),
                RT_log = log(RT_sec))%>%
  ggplot2::ggplot(., aes(x=RT_log)) + 
    geom_histogram(aes(fill=cond), alpha=0.5, bins=60) + 
    facet_grid(~Subject) +  # One panel per id
    coord_cartesian(xlim=c(-2, 1))


# fit a three-level hierarchical model for RT, didn't specify the prior
RT_val_m1 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec ~ Valence*ismatch_num + 
              (Valence*ismatch_num | ExpID_new) +   
              (Valence*ismatch_num  | ExpID_new:Subject),
            family=shifted_lognormal(),
            data = .,
            control = list(adapt_delta = .95),
            cores = parallel::detectCores(),
            file = here::here("glmmModels/RT_val_EffectCode_3_level"))
#plot(RT_val_m1, "b_")
summary(RT_val_m1)  # ndt = 0 there fore, we used lognormal.
pp_check(RT_val_m1)

#Population-Level Effects: 
#                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#Intercept                  -0.40      0.06    -0.52    -0.27 1.01      837     1301  # baseline: mismatch:neutral
#ValenceBad                  0.01      0.00     0.00     0.02 1.00     1752     2540  # mismatch:bad - mismatch:neutral = 0.01
#ValenceGood                -0.03      0.00    -0.04    -0.02 1.00     1237     2219  # mismatch:Good - mismatch:neutral = -0.03
#ismatch_num                -0.07      0.01    -0.09    -0.06 1.00     1638     1957  # match:neutral - mismatch:neutral = -0.07
#ValenceBad:ismatch_num      0.02      0.01     0.00     0.04 1.00     1597     2380  # match:bad - ValenceBad -ismatch_num = 0.02
#ValenceGood:ismatch_num    -0.05      0.01    -0.07    -0.03 1.00     1424     1775  # match:good - ValenceGood- ismatch_num = -0.05

# Mismatch:Neutral - Intercept = -0.4
# Mismatch:Bad     - Intercept  + ValenceBad = -0.4 + 0.01 = -0.39
# Mismatch:Good    - Intercept  + ValenceGood = -0.4 - 0.03 = -0.43
# Match: Neutral   - Intercept  + ismatch_num = -0.4 - 0.07 = -0.47
# Match: Bad       - Intercept  + ismatch_num + ValenceBad+ ValenceBad:ismatch_num = -0.4 + 0.01 + 0.02 =  -0.37 
# Match: Good      - Intercept  + ismatch_num + ValenceGood+ ValenceGood:ismatch_num = -0.4 + (-0.03) + (-0.05) = -0.48

# log normal distribution, dummy coding
RT_val_m2 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m2"))
summary(RT_val_m2)


# log normal distribution, with truncated distribution, , dummy coding
RT_val_m3_trunc <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec|trunc(lb = 0.2, ub = 1.1) ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m3_trunc"))
summary(RT_val_m3_trunc)
pp_check(RT_val_m3_trunc)
#plot(RT_val_m3_trunc, "b_")

# compare three models
loo(RT_val_m1, RT_val_m2, RT_val_m3_trunc)
bayes_factor(RT_val_m1,RT_val_m2)
#Monte Carlo SE of elpd_loo is 0.4.

#All Pareto k estimates are good (k < 0.5).
#See help('pareto-k-diagnostic') for details.

#Model comparisons:
#                elpd_diff se_diff
#RT_val_m1          0.0       0.0 
#RT_val_m2         -5.6       3.3 
#RT_val_m3_trunc -590.6      34.8 

# Get the variables in the model 1
RT_var_name_m1 <- tidybayes::get_variables(RT_val_m1)

df_m1_post_rt_exp <- RT_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

rt_pop_mean <- RT_val_m1 %>%
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
                          `b_ValenceGood:ismatch_num`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
rt_pop_post <- RT_val_m1 %>% 
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
                          `b_ValenceGood:ismatch_num`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
rt_post_tmp <- merge(rt_pop_post, df_rt_m1_post_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_rt_plot <- rt_pop_post %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., rt_post_tmp) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)#, # reverse the order b/c plot function auto reverse.
                #term = mosaic::derivedFactor("Neutral_NM" = (term == "Intercept"),
                #                             "diff_BN_NM" = (term == "ValenceBad"),
                #                             "diff_GN_NM" = (term == "ValenceGood"),
                #                             "Neutral_M" = (term == "ismatch_num"),
                #                             "Bad_M_int" = (term == "ValenceBad:ismatch_num"),
                #                             "Good_M_int" = (term == "ValenceGood:ismatch_num"),
                #                             .method ="first", .default = NA),
                #term = factor(term, levels = c("Bad_NM", "Neutral_NM", "Good_NM",
                 #                              "Bad_M", "Neutral_M", "Good_M"))
                ) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = ValenceGood - ValenceBad,               # calculate the differences between coditions
                diff_GN_NM = ValenceGood,
                diff_BN_NM = ValenceBad,
                diff_GN_M = ValenceGood + `ValenceGood:ismatch_num`,
                diff_BN_M = ValenceBad + `ValenceBad:ismatch_num`,
                diff_GB_M = diff_GN_M - diff_BN_M) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))

df_m1_rt_plot %>% 
  dplyr::group_by(condition, term_diff, .chain) %>%
  dplyr::tally()

df_m1_rt_mean <- df_m1_rt_plot %>%
  #tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
  #                        `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
  #                        `b_ValenceGood:ismatch_num`) %>%
  group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(value)  # get the high density continuous intervals


# plot the posterior of mismatch
df_m1_rt_plot  %>%
  dplyr::filter(str_detect(term_diff, '_NM')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# plot the posterior of matching trials
df_m1_rt_plot %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# Get the variables in the model 3
RT_var_name_m3 <- tidybayes::get_variables(RT_val_m3_trunc)

df_m3_post_rt_exp <- RT_val_m3_trunc %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

rt_pop_mean <- RT_val_m3_trunc %>%
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
rt_pop_post <- RT_val_m3_trunc %>% 
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
rt_post_tmp <- merge(rt_pop_post, df_m3_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m3_rt_plot <- rt_pop_post %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., rt_post_tmp) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)#, # reverse the order b/c plot function auto reverse.
                ) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = ValenceGood - ValenceBad,               # calculate the differences between coditions
                diff_GN_NM = ValenceGood,
                diff_BN_NM = ValenceBad,
                diff_GN_M = ValenceGood + `ValenceGood:ismatch`,
                diff_BN_M = ValenceBad + `ValenceBad:ismatch`,
                diff_GB_M = diff_GN_M - diff_BN_M) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))

df_m3_rt_plot %>% 
  dplyr::group_by(condition, term_diff, .chain) %>%
  dplyr::tally()

df_m3_rt_mean <- df_m3_rt_plot %>%
  group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(value)  # get the high density continuous intervals


# plot the posterior of mismatch
df_m3_rt_plot  %>%
  dplyr::filter(str_detect(term_diff, '_NM')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# plot the posterior of matching trials
df_m3_rt_plot %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

```

```{r second meta,echo=FALSE,results='hide'}
# Results part 2: with self-referential, included experiments: 3a, 3b, 6b, 7a, 7b

# Combine the data  ----
df.meta_d_2 <- rbind(df3a.meta.d, df3b.meta.d, df6b.meta.d, df7a_m.meta.d, df7b_m.meta.d) 
df.meta_rt_2 <- rbind(df3a.meta.rt, df3b.meta.rt, df6b.meta.rt, df7a_m.meta.rt, df7b_m.meta.rt)

# Calculate the mean, sd, n, and r ----
# for estimating the effect size and SE of effect size.
effectList_2 <- c('Good_Bad_S','Good_Neut_S','Neut_Bad_S',
                'Good_Bad_O','Good_Neut_O','Neut_Bad_O')

df.ES_2 <- data.frame(matrix(, nrow=length(unique(df.meta_d_2$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df.meta_d_2$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df.meta_d_2$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df.meta_d_2$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df.meta_rt_2 %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df.meta_d_2 %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Neut_Bad_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Neut_Bad_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_2$M1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_2$SD1[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_2$M2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_2$SD2[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_2$N[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_2$r[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_2$ES[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,1]
      df.ES_2$ES.var[df.ES_2$DVtype == DVName & df.ES_2$ExpID == expName & df.ES_2$Effect == effectName] <- tmp2[1,2]
    }
  }
}

# Do the meta ----
# info about participants
df.ES_2_sum <- df.ES_2 %>% 
  dplyr::group_by(DVtype, Effect) %>% 
  tidyr::drop_na() %>% 
  dplyr::summarise(Nexp = length(unique(ExpID)), Nsubj = sum(N, na.rm = T))

df.res.meta_2 <- data.frame(matrix(, nrow= (2*3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = (2*3)),
                Effect = rep(effectList_2, 2),
                N_exp = NA, Cohen_d = NA, se = NA, CI_low = NA, CI_upp = NA, pval = NA)

# meta -analysis
for (DVName in c('RT','dprime')){
  for (effectName in effectList_2){
    df.res.meta <- df.ES_2 %>%
      dplyr::filter(DVtype == DVName & Effect == effectName) %>%
      tidyr::drop_na()
  
    tmp.meta.res <- metafor::rma(yi = df.res.meta$ES,
                           vi = df.res.meta$ES.var,
                           slab = df.res.meta$ExpID)
    df.res.meta_2$N_exp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$k
    df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$beta
    df.res.meta_2$se[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$se
    df.res.meta_2$CI_low[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.lb
    df.res.meta_2$CI_upp[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$ci.ub
    df.res.meta_2$pval[df.res.meta_2$DVtype == DVName & df.res.meta_2$Effect == effectName] <- tmp.meta.res$pval
  }
}

# plot the effect size  ----
df.res.meta_2 <- df.res.meta_2 %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Neut_Bad_S",
                                  "Self-Ref.", "Other-Ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Neut_Bad")))

df.res_meta_pdata <- rbind(df.res.meta_1, df.res.meta_2) %>%
  dplyr::mutate(Identity = factor(Identity, levels = c("No-Ref.", "Self-Ref.", "Other-Ref.")),
                EffectType = factor(EffectType, levels = c("Good_Bad", "Good_Neut", "Neut_Bad" )))

```

## Effect of moral valence

```{r plot-all-effect, fig.cap="Effect size (Cohen's *d*) of Valence.", fig.width=12, warning=FALSE}
#p_meta_val <- 
  df.res_meta_pdata %>%
  #dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=DVtype, y=Cohen_d, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  #ggtitle('Valence effect') +
  #geom_bar(stat="identity", color=NA, 
  #         position=position_dodge()) +
  #geom_errorbar(aes(ymin=Cohen_d - 1.96*se, ymax = Cohen_d + 1.96*se), width=.2,
  #               position=position_dodge(.9)) +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  apatheme +
  facet_wrap( ~ Identity, nrow = 1)
```
In this part, we synthesized results from experiment 1a, 1b, 1c, 2, 5 and 6a. Data from 192 participants were included in these analysis. We found differences between positive and negative conditions on RT was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Bad']`]; on *d'* was Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Bad']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Good_Neut']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Good_Neut']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'RT' & df.res.meta_1$Effect =='Neut_Bad']`]; *d'*: Cohen's *d* = `r df.res.meta_1$Cohen_d[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']` $\pm$ `r df.res.meta_1$se[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']`, 95% CI [`r df.res.meta_1$CI_low[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']` `r df.res.meta_1$CI_upp[df.res.meta_1$DVtype == 'dprime' & df.res.meta_1$Effect =='Neut_Bad']`]. See Figure \@ref(fig:plot-all-effect) left panel.

## Interaction between valence and self-reference
In this part, we combined the experiments that explicitly manipulated the self-reference and valence, which includes 3a, 3b, 6b, 7a, and 7b. For the positive versus negative contrast, data were from five experiments whith 178 participants; for positive versus neutral and neutral versus negative contrasts, data were from three experiments with 108 participants.

In most of these experiments, the interaction between self-reference and valence was signficant (see results of each experiment in supplementary materials). In the mini-meta-analysis, we analyzed the valence effect for self-referential condition and other-referential condition separately.

For the self-referential condition, we found the same pattern as in the first part of results. That is we found significant differences between positive and neutral as well as positive and negative, but not neutral and negative. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_S']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_S']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_S']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_S']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_S']`]. See Figure \@ref(fig:plot-all-effect) the middle panel.

For the other-referential condition, we found that only the difference between positive and negative on RT was significant, all the other conditions were not. The effect size of RT between positive and negative is Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Bad_O']`]; on *d'* was Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Bad_O']`]. The effect was also observed between positive and neutral condition, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Good_Neut_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Good_Neut_O']`]. And the difference between neutral and bad conditions are not significant, RT: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'RT' & df.res.meta_2$Effect =='Neut_Bad_O']`]; *d'*: Cohen's *d* = `r df.res.meta_2$Cohen_d[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']` $\pm$ `r df.res.meta_2$se[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']`, 95% CI [`r df.res.meta_2$CI_low[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']` `r df.res.meta_2$CI_upp[df.res.meta_2$DVtype == 'dprime' & df.res.meta_2$Effect =='Neut_Bad_O']`]. See Figure \@ref(fig:plot-all-effect) right panel.

## Generalizibility of the valence effect
In this part, we reported the results from experiment 4 in which either moral valence or self-reference were manipulated as task-irrelevant stimuli. 

```{r analyzing exp4a, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
df.ES_4a <- data.frame(matrix(, nrow=length(unique(df4a.meta.d$ExpID))*length(effectList_2)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4a.meta.d$ExpID))*length(effectList_2)),
                ExpID  = rep(rep(unique(df4a.meta.d$ExpID), each = length(effectList_2)), 2),
                Effect = rep(effectList_2, length(unique(df4a.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4a.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4a.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_2){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Good_Bad_S'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Good_Neut_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Neut_Bad_S'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Bad_O'){
        if (!all(is.na(tmpdata$Identity))){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Good_Neut_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence )
          {
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }
      else if (effectName == 'Neut_Bad_O'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
      }
      
      M1  <- mean(dataCond1$Value) -> df.ES_4a$M1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4a$SD1[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_4a$M2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4a$SD2[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4a$N[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4a$r[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4a$ES[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,1]
      df.ES_4a$ES.var[df.ES_4a$DVtype == DVName & df.ES_4a$ExpID == expName & df.ES_4a$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4a <- df.ES_4a %>%
  dplyr::mutate(Identity = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Neut_S" | Effect == "Neut_Bad_S",
                                  "Self-ref.", "Other-ref."),
                EffectType = ifelse(Effect == "Good_Bad_S" | Effect == "Good_Bad_O", "Good_Bad",
                                    ifelse(Effect == "Good_Neut_S" | Effect == "Good_Neut_O", "Good_Neut", "Neut_Bad")),
                Identity = factor(Identity, levels = c("Self-ref.", "Other-ref.")))

p_df_4a <- df.ES_4a %>%
  #dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=DVtype, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('A: Valence effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  apatheme +
  facet_wrap(~Identity, nrow = 1)

#p_df_4a
```

```{r 'plot_exp4a_effect', fig.cap="Effect size (Cohen's *d*) of Valence in Exp4a.", warning=FALSE}
#multiplot(p_meta_val_1, p_meta_val_2_self,p_meta_val_2_other, cols = 3)
p_df_4a
```
For exmperiment 4a, when self-reference was the target and moral valence was task-irrelevant, we found that only under the implicit self-referential condition, i.e., when the moral words were presented as task irrelevant stimuli, there was the main effect of valence and interaction between valence and reference for both *d* prime and RT (See supplementary resuls for the detailed statistics). For *d* prime, we found good-self condition (`r df.ES_4a$M1[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD1[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']`) had higher *d* prime than bad-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Bad_S']`); good self condition was also higher than neutral self (`r df.ES_4a$M2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Neut_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'dprime' & df.ES_4a$Effect == 'Good_Neut_S']`) but there was not statistically significant, while the neutral-self condition was higher than bad self condition and not significant neither. For reaction times, good-self condition (`r df.ES_4a$M1[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD1[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']`) were faster relative to bad-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Bad_S']`), and over neutral-self condition (`r df.ES_4a$M2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Neut_S']` $\pm$ `r df.ES_4a$SD2[df.ES_4a$DVtype == 'RT' & df.ES_4a$Effect == 'Good_Neut_S']`). The difference between neutral-self and bad-self conditions were not significant. However, for the other-referential condition, there was no significant differences between different valence conditions.

```{r analyzing exp4b, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
effectList_3 <- c('Self_Other_G','Self_Other_N', 'Self_Other_B')

df.ES_4b <- data.frame(matrix(, nrow=length(unique(df4b.meta.d$ExpID))*length(effectList_3)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df4b.meta.d$ExpID))*length(effectList_3)),
                ExpID  = rep(rep(unique(df4b.meta.d$ExpID), each = length(effectList_3)), 2),
                Effect = rep(effectList_3, length(unique(df4b.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df4b.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df4b.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_3){
      tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
      
      if (effectName == 'Self_Other_G'){
        
        if (!all(is.na(tmpdata$Identity))){
          #print(paste('processing Good_Bad_S of ', expName, sep = ''))
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Good" & Identity == 'Other')  
          }
        else{
            #print(paste('Skip Good_Bad_S of ', expName, sep = ''))
          next
          }
        }
      else if (effectName == 'Self_Other_N'){
        if (!all(is.na(tmpdata$Identity)) & 'Neutral' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral" & Identity == 'Other')  
          }
        else{
          next
          }
        }  
      else if (effectName == 'Self_Other_B'){
        if (!all(is.na(tmpdata$Identity)) & 'Bad' %in% tmpdata$Valence ){
          dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Self')
          dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad" & Identity == 'Other')  
          }
        else{
          next
          }
        }

      
      M1  <- mean(dataCond1$Value) -> df.ES_4b$M1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_4b$SD1[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_4b$M2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_4b$SD2[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_4b$N[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_4b$r[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_4b$ES[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,1]
      df.ES_4b$ES.var[df.ES_4b$DVtype == DVName & df.ES_4b$ExpID == expName & df.ES_4b$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_4b <- df.ES_4b %>%
  dplyr::mutate(Val = ifelse(Effect == "Self_Other_G", "Good",
                                  ifelse(Effect == "Self_Other_N", 'Neutral', 'Bad')),
                EffectType = 'Self_Other',
                Val = factor(Val, levels = c("Good", "Neutral", "Bad")))

p_df_4b_val <- df.ES_4b %>%
  #dplyr::filter(Identity == "Self") %>%
  ggplot(., aes(x=DVtype, y=ES, color=Val, fill=Val)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('Self-ref effect') +
  coord_cartesian(ylim=c(-1.1, 1.1))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  apatheme

p_df_4b_val
```
For experiemnt 4b, when valence was the target and the reference was task-irrelevant, we found a strong valence effect (see supplementary results). In this experiment, the advantage of good-self conition can only be distangled by comparing the self-referential and other-referential conditions while controling the valence condition. We only found this modulation effect on RT. The RT of good-self (`r df.ES_4b$M1[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G']` $\pm$ `r df.ES_4b$SD1[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G']`) were faster relative to good-other condition (`r df.ES_4b$M2[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G']` $\pm$ `r df.ES_4b$SD2[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G']`), Cohen's *d* = `r df.ES_4b$ES[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G']`, 95% CI[`r df.ES_4b$ES[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G'] -  1.96*sqrt(df.ES_4b$ES.var[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G'])` `r df.ES_4b$ES[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G'] +  1.96*sqrt(df.ES_4b$ES.var[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_G'])`]. However, neutral-self (`r df.ES_4b$M1[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N']` $\pm$ `r df.ES_4b$SD1[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N']`) were faster relative to good-other condition (`r df.ES_4b$M2[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N']` $\pm$ `r df.ES_4b$SD2[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N']`), Cohen's *d* = `r df.ES_4b$ES[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N']`, 95% CI[`r df.ES_4b$ES[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N'] -  1.96*sqrt(df.ES_4b$ES.var[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N'])` `r df.ES_4b$ES[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N'] +  1.96*sqrt(df.ES_4b$ES.var[df.ES_4b$DVtype == 'RT' & df.ES_4b$Effect == 'Self_Other_N'])`]. The difference between bad-self and bad-other was not significant. All the differences between self-referential and other-referential were not significant for *d* prime.

## Specificity of valence effect

```{r analyzing exp5, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
effectList_exp5 <- c('Good_Bad_Mrl','Good_Neut_Mrl','Neut_Bad_Mrl',
                     'Good_Bad_BP','Good_Neut_BP','Neut_Bad_BP',
                     'Good_Bad_BS','Good_Neut_BS','Neut_Bad_BS',
                     'Good_Bad_Emo','Good_Neut_Emo','Neut_Bad_Emo')

df.ES_5 <- data.frame(matrix(, nrow=length(unique(df5.meta.d$ExpID))*length(effectList_exp5)*2, ncol=0)) %>%
  dplyr::mutate(DVtype = rep(c('RT', 'dprime'), each = length(unique(df5.meta.d$ExpID))*length(effectList_exp5)),
                ExpID  = rep(rep(unique(df5.meta.d$ExpID), each = length(effectList_exp5)), 2),
                Effect = rep(effectList_exp5, length(unique(df4a.meta.d$ExpID))*2),
                M1 = NA, SD1 = NA, M2 = NA, SD2 = NA, N = NA, r = NA, ES = NA, ES.var = NA)

for (DVName in c('RT','dprime')){
  if (DVName == 'RT'){
    metaData <- df5.meta.rt %>% dplyr::filter(Matchness == "Match") %>% dplyr::rename(Value = RT)
  } else{
    metaData <- df5.meta.d %>% dplyr::rename(Value = dprime)
  }
  
  for (expName in unique(metaData$ExpID)){
    for (effectName in effectList_exp5){
      if (effectName == 'Good_Bad_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Neut_Bad_Mrl'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Morality')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
      }
      
      else if (effectName == 'Good_Bad_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Neut_Bad_BP'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Person')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
      }
      
      else if (effectName == 'Good_Bad_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Neut_Bad_BS'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Scene')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
      }
      
      else if (effectName == 'Good_Bad_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")  
        }
      else if (effectName == 'Good_Neut_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Good")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Neutral")  
        }  
      else if (effectName == 'Neut_Bad_Emo'){
        tmpdata <- metaData %>% dplyr::filter(ExpID == expName & Domain == 'Emotion')
        dataCond1 <- tmpdata %>% dplyr::filter(Valence == "Neutral")
        dataCond2 <- tmpdata %>% dplyr::filter(Valence == "Bad")
        }
      
      M1  <- mean(dataCond1$Value) -> df.ES_5$M1[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      SD1 <- sd(dataCond1$Value)   -> df.ES_5$SD1[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] 
      M2  <- mean(dataCond2$Value) -> df.ES_5$M2[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      SD2 <- sd(dataCond2$Value)   -> df.ES_5$SD2[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      N   <- length(unique(dataCond2$Subject)) -> df.ES_5$N[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName]
      r   <- cor(dataCond1$Value,dataCond2$Value) -> df.ES_5$r[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] 
      tmp2 <- d.sgpp(m.1 = M1, m.2 = M2, sd.1 = SD1, sd.2 = SD2,n = N, r = r)
      df.ES_5$ES[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] <- tmp2[1,1]
      df.ES_5$ES.var[df.ES_5$DVtype == DVName & df.ES_5$ExpID == expName & df.ES_5$Effect == effectName] <- tmp2[1,2]
    }
  }
}

df.ES_5 <- df.ES_5 %>%
  dplyr::mutate(Domain = ifelse(Effect == "Good_Bad_Mrl" | Effect == "Good_Neut_Mrl" | Effect == "Neut_Bad_Mrl",
                                  "Mrl",
                                ifelse(Effect == "Good_Bad_BP" | Effect == "Good_Neut_BP" | Effect == "Neut_Bad_BP",
                                  "AP",
                                  ifelse(Effect == "Good_Bad_BS" | Effect == "Good_Neut_BS" | Effect == "Neut_Bad_BS",
                                  "AS", 'Emo'))),
                Domain = factor(Domain, levels = c("Mrl", "AP", "AS", "Emo")),
                EffectType = ifelse(Effect == "Good_Bad_Mrl" | Effect == "Good_Bad_BP"  | Effect == "Good_Bad_BS"  | Effect == "Good_Bad_Emo", "Pos_Neg",
                                    ifelse(Effect == "Good_Neut_Mrl" | Effect == "Good_Neut_BP" | Effect == "Good_Neut_BS" | Effect == "Good_Neut_Emo", "Pos_Neut", "Neut_Neg")),
                EffectType = factor(EffectType, levels = c("Pos_Neg", "Pos_Neut", "Neut_Neg")))

p_df_5_RT <- df.ES_5 %>%
  #dplyr::filter(DVtype == "RT") %>%
  ggplot(., aes(x=DVtype, y=ES, color=EffectType, fill=EffectType)) + 
  geom_pointrange(aes(ymin=ES - 1.96*sqrt(ES.var), ymax = ES + 1.96*sqrt(ES.var)), 
                  position = position_dodge(width = 0.4),
                  shape=18, size=1) +
  geom_hline(yintercept=0, size=1, color='black') +
  ggtitle('Valence effect across different domains') +
  coord_cartesian(ylim=c(-1.5, 1.5))+
  scale_color_brewer(palette = "Dark2")+
  scale_fill_brewer(palette = "Dark2")+
  ylab(expression(paste("Cohen's ",italic("d"), sep = ' ')))+
  facet_wrap( ~ Domain, ncol = 4) +
  apatheme 
```
In this part, we analyzed the results from experiment 5, which included positive, neutral, and negative valence from four different domains: morality, emotion, aesthetics of human, and aesthetics of scene. We found interaction between valence and domain for both *d* prime and RT (matched trials). A common pattern appeared in all four domains: each domain showed a binary results instead of gradian on both *d* prime and RT. For morality, aesthetics of human, and aesthetics of scene, the positive conditions had advantages over both neutral and negative conditions (greater *d* prime and faster RT), and neutral and negative conditions didn't differ from each other. But for the emotional stimuli, it was the positive and neutral had advantage over negative conditions, while positive and neutral conditions were not significantly different. See supplementary materials for detailed statistics. Also note that the effect size in moral domain is smaller than the aesthetic domains (beauty of people and beauty of scene).

## Correlation analyses
As the reliability of the quesetionnaire can be found in [@Liu_2020_JOPD]. Then we calculated the correlation between the data from behavioral task and the questionnaire data. 

For the behavioral task part, we derived different indices. First, we used the mean and SD of the RT data from each participants of each condition. We included the RT variation because it has been shown to be meaningful as individual differences [Jensen, 1992; Ouyang et al., 2017]. Second, we used drift diffusion model to estimate four parameters of DDM for each participants. Third, we also calculated the differences between different conditions (valence effect: good-self vs. bad-self, good-self vs. neutral-self, bad-self vs. neutral-self; good-other vs. bad-other, good-other vs. neutral-other, bad-other vs. neutral-other; Self-reference effect: good-self vs. good-other, neutral-self vs. neutral-other, bad-self vs. bad-other), as indexed by Cohen's d and se of Cohen's *d*.

The DDM analyses were finished by HDDM, as reported in Hu et al., (2019: https://psyarxiv.com/9fczh/). That is, we used the reponse code approach, matched response were coded as 1 and mismatched responses were coded as 0. To fully explore all parameters, we allow all four parameters of DDM free to vary. We then extracted the estimation of all the four parameters for each participants for the correlation analyses.

For the questinnaire part, we are most interested in the self-rated distance between different person and self-evaluation related questionnaires: self-esteem, moral-self identity, and moral self-image. Other questionnaires (e.g., personality) were not planned to correlated with behavioral data were not included.


```{r correlation analysis,echo=FALSE, results='hide', warning=FALSE, message=FALSE}
# get data for valence effect ---- 
## mean RT, SD of RT, and d prime for data without reference
tmp1 <- df.meta_rt_1 %>%
  dplyr::filter(Matchness == "Match" & Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = c(RT, RT_SD))
  
tmp2 <- df.meta_d_1 %>%
  dplyr::filter(Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = dprime) %>%
  dplyr::rename(dprime_Good = Good,
                dprime_Neut = Neutral,
                dprime_Bad = Bad)
  
df.meta_1_wide <- merge(tmp1,tmp2); rm(tmp1,tmp2)

## paramters of HDDM for the data without reference
## read all the file name.
params.list <- list.files(file.path('.', 'HDDM'), pattern = '*_hddm_params.csv')
params.expname <- data.frame(params.list) %>%
  tidyr::separate(params.list, c('expName','B','C'),sep = '_') %>%
  dplyr::select(expName) %>%
  dplyr::pull()

df_hddm_ls_1 <- params.list[c(1:4, 9:10)]

#rm(df_hddm_param_1)
for (indx in 1:6){
  #expName_tmp <- strsplit(df_hddm_ls_1[indx], '[_]')[[1]][1]
  if (indx == 5 ){
    hddm_params_tmp <- read.csv(paste(".\\HDDM\\", df_hddm_ls_1[indx], sep = ''), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::filter(domain == "Morality") %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')  
    
  } else {
    
    hddm_params_tmp <- read.csv(paste(".\\HDDM\\", df_hddm_ls_1[indx], sep = ''), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')   # %>%
      #dplyr::mutate(ExpID = 'Exp1a')
  }
  
  if (exists('df_hddm_param_1')) {
    df_hddm_param_1 <- rbind(df_hddm_param_1, hddm_params_tmp) 
  } else {
    df_hddm_param_1 <- hddm_params_tmp
  }
  
}

df.meta_1_wide <- merge(df.meta_1_wide, df_hddm_param_1) %>%
  dplyr::select(-c(Domain, Identity, Matchness))

## Get data for interaction between ID & Val ----
## mean RT, SD of RT, and d prime for data without reference
tmp1 <- df.meta_rt_2 %>%
  dplyr::filter(Matchness == "Match" & Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = c(RT, RT_SD))
  

tmp2 <- df.meta_d_2 %>%
  dplyr::filter(Domain == 'Morality') %>%
  tidyr::pivot_wider(names_from = c(Valence), values_from = dprime) %>%
  dplyr::rename(dprime_Good = Good,
                dprime_Neut = Neutral,
                dprime_Bad = Bad)
  
df.meta_2_wide <- merge(tmp1,tmp2); rm(tmp1,tmp2)

## paramters of HDDM 
## read all the file name.
df_hddm_ls_2 <- params.list[c(5, 6, 11:13)]

#rm(df_hddm_param_2)  # in case the variable exist in the env.
for (indx in 1:5){
  #expName_tmp <- strsplit(df_hddm_ls_1[indx], '[_]')[[1]][1]
  hddm_params_tmp <- read.csv(file.path("HDDM", df_hddm_ls_2[indx], sep = ''), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
    dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val, Identity = id) %>%
    dplyr::select(Subject, Matchness, Identity, Valence, knode_name, mean) %>%
    tidyr::drop_na() %>%
    tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
    dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
    tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')   # %>%
    #dplyr::mutate(ExpID = 'Exp1a')
  if (indx == 4 | indx == 5){
    hddm_params_tmp <- hddm_params_tmp %>%
      dplyr::mutate(Neutral_a = NA,
                    Neutral_t = NA,
                    Neutral_v = NA) %>%
      dplyr::select(Subject, Identity, Bad_a, Good_a, Neutral_a, Bad_v, Good_v, Neutral_v, Bad_t, Good_t,
                    Neutral_t)
  }
  
  if (exists('df_hddm_param_2')) {
    df_hddm_param_2 <- rbind(df_hddm_param_2, hddm_params_tmp) 
  } else {
    df_hddm_param_2 <- hddm_params_tmp
  }
}

df.meta_2_wide <- merge(df.meta_2_wide, df_hddm_param_2) %>%
  dplyr::select(-c(Domain, Matchness))

df.meta_1_wide <- df.meta_1_wide %>%
  dplyr::mutate(Identity = NA) %>%
  dplyr::select(colnames(df.meta_2_wide))

df.meta_all_wide <- df.meta_2_wide %>%
  dplyr::filter(Identity == "Self") %>%
  rbind(df.meta_1_wide, .)

#library(mosaic) # using this library for its derivedFactor function
# prepare questionnare data
#df.scales <- read.csv(here::here("Scale_data", "FADGS_dataset4_1_clean.csv"), header = TRUE, sep = ",",
#                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
#  dplyr::mutate(expID = mosaic::derivedFactor("Exp1a" = (expID == "exp1.0"), 
#                                      "Exp1b" = (expID == "exp1.1"),
#                                      "Exp3a" = (expID == "exp3"),
#                                      "Exp3b" = (expID == "exp3.1"),
#                                      "Exp4a" = (expID == "exp4.1"),
#                                      "Exp4b" = (expID == "exp4.2"),
#                                      "Exp5" = (expID == "exp5.2"),
#                                      "Exp6b" = (expID == "exp6.2"),
#                                      "Exp7a" = (expID == "exp7.1"),
#                                      "Exp7b" = (expID == "exp7r"),
#                                      "Exp_dpr" = (expID == "exp6"),
#                                      .method ="first", .default = NA),
#                expID = as.character(expID))

## get the questionnaire names
# Self-esteem
SlfEstNames <- c("SES1","SES2","SES3","SES4","SES5","SES6","SES7","SES8","SES9","SES10")
df.scales %>%
  dplyr::select(SlfEstNames) %>%
  psych::omega(.)

# moral identity
mrlIdNames <- c("morId_1","morId_2","morId_3","morId_4", "morId_5","morId_6",
                "morId_7","morId_8","morId_9","morId_10","morId_11","morId_12",
                "morId_13","morId_14","morId_15","morId_16")
mrlIdIntNames <- c("morId_1","morId_2","morId_5","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdExtNames <- c("morId_3","morId_4", "morId_6", "morId_7", "morId_9","morId_10",
                   "morId_15", "morId_16")

df.scales %>%
  dplyr::select(mrlIdNames) %>%
  psych::omega(.)

# moral self images
mrlslfImgNames <- c("morSlfImg_1","morSlfImg_2","morSlfImg_3","morSlfImg_4",
                    "morSlfImg_5","morSlfImg_6","morSlfImg_7","morSlfImg_8","morSlfImg_9")

df.scales %>%
  dplyr::select(mrlslfImgNames) %>%
  psych::omega(.)

# personal distance
perDistNames <- c("SelfSelf", 
                  "SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "SelfStra_1", "SelfStra_2", "SelfStra_3", "SelfStra_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

# calculate the average score of each relevant scale
df.q_scores <- df.scales %>%
  dplyr::mutate(SlfEst = rowMeans(.[, SlfEstNames],na.rm = F),
                mrlIdInt = rowMeans(.[, mrlIdIntNames], na.rm = F),
                mrlIdExt = rowMeans(.[, mrlIdExtNames], na.rm = F),
                mrlslfImg = rowMeans(.[, mrlslfImgNames], na.rm = F),
                ) %>%
  dplyr::select(subjID, SlfEst, mrlIdInt, mrlIdExt, mrlslfImg)

df.scales %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  head()

# normalize the personal distance, way 1: 
# (1) calculate the mean distance of all distance ratings, grand_mean
# (2) calculate the mean distance of each pair, condition_mean
# (3) normalize the condition_mean: condition_mean/grand_mean
df.perdist <- df.scales %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  dplyr::mutate(sumRaw = rowMeans(.[3:31], na.rm = T),
                SelfSelfraw = SelfSelf,
                SelfGoodraw = rowMeans(.[grep("SelfGood", names(.))], na.rm = T),
                SelfNeutraw = rowMeans(.[grep("SelfNeut", names(.))], na.rm = T),
                SelfBadraw  = rowMeans(.[grep("SelfBad", names(.))], na.rm = T),
                SelfStraraw = rowMeans(.[grep("SelfStra", names(.))], na.rm = T),
                GoodNeutraw = rowMeans(.[grep("GoodNeut", names(.))], na.rm = T),
                GoodBadraw  = rowMeans(.[grep("GoodBad", names(.))], na.rm = T),
                NeutBadraw  = rowMeans(.[grep("NeutBad", names(.))], na.rm = T)) %>%
  dplyr::select(expID, subjID, sumRaw, SelfSelfraw, 
                SelfGoodraw, SelfNeutraw, SelfBadraw,
                SelfStraraw, GoodNeutraw, GoodBadraw, NeutBadraw) %>%
  dplyr::mutate(Self_Self = SelfSelfraw/sumRaw,
                Self_Good = SelfGoodraw/sumRaw,
                Self_Neut = SelfNeutraw/sumRaw,
                Self_Bad = SelfBadraw/sumRaw,
                Self_Stra = SelfStraraw/sumRaw, 
                Good_Neut = GoodNeutraw/sumRaw, 
                Good_Bad = GoodBadraw/sumRaw, 
                Neut_Bad = NeutBadraw/sumRaw) %>%
  dplyr::select(subjID, Self_Self, Self_Good, Self_Neut, Self_Bad,
                Self_Stra, Good_Neut, Good_Bad, Neut_Bad) %>%
  dplyr::select(-Self_Stra,-Self_Self)

#------------------- try RSA: start ------------------------------
# select data from exp1a
df.perdist_part1 <- df.perdist %>%
      dplyr::filter(subjID %in% df_moral$Subject)

# select the first participants
# personal distance matrix
#df.perdist_exp1a.sub1_dist0 <- df.perdist_exp1a %>%
#      dplyr::filter(subjID == 1051) %>%
#      dplyr::select(Good_Neut:Neut_Bad) %>%
#      tidyr::pivot_longer(cols = Good_Neut:Neut_Bad, 
#                      names_to = "condition",
#                      values_to = "distance_rate") 

dist_mental <- function(df_perdist_subj){
  df.perdist_subj <- df_perdist_subj %>%
      dplyr::select(Good_Neut:Neut_Bad) %>%
      tidyr::pivot_longer(cols = Good_Neut:Neut_Bad, 
                      names_to = "condition",
                      values_to = "distance_rate") 
}

#tmp <- dist_mental(df.perdist_exp1a[df.perdist_exp1a$subjID == 1051,])

tmp <- df.perdist_part1 %>%
  split(.$subjID) %>%
  map(., dist_mental)  %>%
  dplyr::bind_rows(., .id = "Subject")

# reaction times matrix
#df.rt_exp1a.sub1_dist0 <- df1a.v_meta %>%
#      dplyr::filter(Subject == 1051 & Matchness == 'Match' & ACC == 1) %>%
#      dplyr::mutate(SD_RT = sd(RT)) %>% 
#      dplyr::group_by(Valence, SD_RT) %>%
#      dplyr::summarise(meanRT = mean(RT)) %>%
#      dplyr::ungroup() %>%
#      tidyr::pivot_wider(names_from = Valence, values_from = meanRT) %>%
#      dplyr::mutate(Good_Neut = abs((Neutral - Good)/SD_RT),
#                    Good_Bad = abs((Bad - Good)/SD_RT),
#                    Neut_Bad = abs((Bad - Neutral)/SD_RT)) %>%
#      dplyr::select(Good_Neut:Neut_Bad) %>%
#      tidyr::pivot_longer(cols = Good_Neut:Neut_Bad, 
#                      names_to = "condition",
#                      values_to = "distance_rt") 

dist_rt <- function(df_subj) {
  dist_subj <- df_subj  %>%
      dplyr::filter(Matchness == 'Match' & ACC == 1) %>%
      dplyr::mutate(SD_RT = sd(RT)) %>% 
      dplyr::group_by(Valence, SD_RT) %>%
      dplyr::summarise(meanRT = mean(RT)) %>%
      dplyr::ungroup() %>%
      tidyr::pivot_wider(names_from = Valence, values_from = meanRT) %>%
      dplyr::mutate(Good_Neut = abs((Neutral - Good)/SD_RT),
                    Good_Bad = abs((Bad - Good)/SD_RT),
                    Neut_Bad = abs((Bad - Neutral)/SD_RT)) %>%
      dplyr::select(Good_Neut:Neut_Bad) %>%
      tidyr::pivot_longer(cols = Good_Neut:Neut_Bad, 
                      names_to = "condition",
                      values_to = "distance_rt") 
}

#tmp <- dist_rt(df1a.v_meta[df1a.v_meta$Subject == 1051,])

tmp2 <- df_moral %>%
  split(.$Subject) %>%
  map(., dist_rt) %>%
  dplyr::bind_rows(., .id = "Subject")

tmp3 <- tmp %>%
  dplyr::left_join(., tmp2, by = c('Subject','condition'))  %>%
  dplyr::group_by(Subject) %>%
  dplyr::summarise(cor_coef =  cor(distance_rt, distance_rate)) %>%
  dplyr::ungroup()

hist(tmp3$cor_coef)

rsa_sub1 <- df.rt_exp1a.sub1_dist0 %>%
      dplyr::full_join(., df.perdist_exp1a.sub1_dist0) #%>%
      
tmp <- stats::cor.test(rsa_sub1$distance_rt, rsa_sub1$distance_rate, method = 'pearson')$estimate

# visualization of the graph
df.perdist_exp1a.sub1_dist1 <- df.perdist_exp1a %>%
      dplyr::filter(subjID == 1050) %>%
      dplyr::select(Good_Neut:Neut_Bad) %>%
      tidyr::pivot_longer(cols = Good_Neut:Neut_Bad, 
                      names_to = "condition",
                      values_to = "distance") %>%
      #dplyr::filter(!is.na(distance)) %>%
      dplyr::add_row(condition = c("Good_Good",
                                "Neut_Neut","Bad_Bad")) %>%
      tidyr::separate(condition, c('var1','var2'), sep = '_') 

df.dist.mat1 <- data.frame(matrix(ncol = 3, nrow = 3))
colnames(df.dist.mat1) <- unique(df.perdist_exp1a.sub1_dist1$var1)
rownames(df.dist.mat1) <- unique(df.perdist_exp1a.sub1_dist1$var1)

for (i in 1:3){
  rname = df.perdist_exp1a.sub1_dist1$var1[i]
  cname = df.perdist_exp1a.sub1_dist1$var2[i]
  value = df.perdist_exp1a.sub1_dist1$distance[i]
  df.dist.mat1[rname, cname] = value
  df.dist.mat1[cname, rname] = value
}

library(qgraph)
qgraph::qgraph(df.dist.mat1, layout='spring', vsize=9)
#------------------- try RSA: end --------------------------------


df.perdist.sum_p <- df.perdist %>%
  tidyr::pivot_longer(cols = Self_Good:Neut_Bad, 
                      names_to = "condition",
                      values_to = "distance") %>%
  #dplyr::mutate(condition = factor(condition,
  #                                 levels = c("GoodNeut", "NeutBad", "GoodBad",
  #                                            "SelfNeut", "SelfGood", "SelfBad"))) %>%
  dplyr::filter(!is.na(distance)) %>%
  dplyr::group_by(condition) %>%
  dplyr::summarise_each(funs(mean, sd, se=sd(.)/sqrt(n())), distance) %>%
  dplyr::select(condition, mean) %>%
  dplyr::add_row(condition = c("Self_Self", "Good_Good",
                                "Neut_Neut","Bad_Bad")) %>%
  tidyr::separate(condition, c('var1','var2'), sep = '_')

# create a distance matrix
df.dist.mat <- data.frame(matrix(ncol = 4, nrow = 4))
colnames(df.dist.mat) <- unique(df.perdist.sum_p$var1)
rownames(df.dist.mat) <- unique(df.perdist.sum_p$var1)

for (i in 1:6){
  rname = df.perdist.sum_p$var1[i]
  cname = df.perdist.sum_p$var2[i]
  value = df.perdist.sum_p$mean[i]
  df.dist.mat[rname, cname] = value
  df.dist.mat[cname, rname] = value
}
df.dist.mat[is.na(df.dist.mat)] <- 0

df.dist.mat_t <- 1/df.dist.mat #/max(df.dist.mat)

library(qgraph)
qgraph(df.dist.mat_t, layout='spring', vsize=9)

pd1 <- position_dodge(0.5)
df.perdist %>%
  tidyr::pivot_longer(cols = SelfSelf:NeutBad, 
                      names_to = "condition",
                      values_to = "distance") %>%
  dplyr::mutate(condition = factor(condition,
                                   levels = c("GoodNeut", "NeutBad", "GoodBad",
                                              "SelfSelf", "SelfNeut", "SelfGood", "SelfBad", "SelfStra"))) %>%
  ggplot2::ggplot(., aes(x = condition, y = distance)) +
   geom_point(aes(x = condition, y = distance, group = subjID),   # plot individual points
              colour = "#000000",
              size = 3, shape = 20, alpha = 0.06)+
   geom_line(aes(x = condition, y = distance, group = subjID),         # link individual's points by transparent grey lines
             linetype = 1, size = 0.8, colour = "#000000", alpha = 0.06) +   
   geom_line(data = df.perdist.sum_p, aes(x = condition, # plot the group means  
                                     y = mean, 
                                     #group = Identity, 
                                     #colour = Identity
                                     ), 
             linetype = 1, position = pd1, size = 2)+
   geom_point(data = df.perdist.sum_p, aes(x = condition, # group mean
                                      y = mean, 
                                      #group = Identity, 
                                      #colour = Identity
                                      ), 
              shape = 18, position = pd1, size = 8) +
   geom_errorbar(data = df.perdist.sum_p, aes(x = condition,  # group error bar.
                                         y = mean, #group = Identity, 
                                         #colour = Identity,
                                         ymin = mean - 1.96*se, 
                                         ymax = mean + 1.96*se), 
                 width = .05, position = pd1, size = 2, alpha = 0.75) 

df.perdist.sum2_p <- df.perdist %>%
  dplyr::mutate(Rang_est_err_s = SelfGood + SelfBad - GoodBad,
                Rang_est_err_ns = GoodNeut + NeutBad - GoodBad) %>% #
  dplyr::select(subjID, Rang_est_err_s, Rang_est_err_ns) %>%
  tidyr::pivot_longer(cols = Rang_est_err_s:Rang_est_err_ns, 
                      names_to = "condition",
                      values_to = "distance") %>%
  dplyr::mutate(condition = factor(condition,
                                   levels = c('Rang_est_err_s', 'Rang_est_err_ns'))) %>%
  dplyr::filter(!is.na(distance)) %>%
  dplyr::group_by(condition) %>%
  dplyr::summarise_each(funs(mean, sd, se=sd(.)/sqrt(n())), distance) 

df.perdist %>% 
  dplyr::mutate(Rang_est_err_s = SelfGood + SelfBad - Good)

# intersection between participant from behavioral task and scales and get the data
subj.common <- intersect(df.scales$subjID, unique(df.meta_all_wide$Subject))  # 253

df.scales.v <- df.scales %>% dplyr::filter(subjID %in% subj.common) %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) # remove columns that only have NA.

df.q_scores.v <- merge(df.q_scores.v, df.perdist)

## calculate correlation ----
df.corr <- merge(df.q_scores.v, df.meta_all_wide, by.x = 'subjID', by.y = 'Subject') %>%
  dplyr::select(-c(14:18)) %>%
  dplyr::select(-c(SelfSelf, SelfStra)) %>%
  dplyr::select(1:5, 8,6,7,10,9,11, 18:20, 24:26, 27:29, 12:17, 21:23) %>%
  dplyr::na_if("NaN")

#library(corrr)
res.cor <- df.corr %>%
  dplyr::select(-c(subjID)) %>%
  as.matrix(.) %>%
  #dplyr::select_if(~sum(!is.na(.)) > 0) %>%
  Hmisc::rcorr(.)

corrplot::corrplot(res.cor$r, method="color", sig.level = .2, order = "FPC")

```
We found that data from behavioral task are closely related, but not with self-reported questionnaire data.

# Discussion

# References
```{r create_r-references, echo=FALSE,results='hide'}
#r_refs(file = "r-references.bib"))
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup

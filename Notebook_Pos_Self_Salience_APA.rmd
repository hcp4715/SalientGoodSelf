---
title             : "Priorization of the morally good in perceptual matching depends on self-relevance"
shorttitle        : "Priorization of the morally good"

author: 
  - name          : "Hu Chuan-Peng"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "School of Psychology, Nanjing Normal University, Ninghai Road 122, Gulou District, 210024 Nanjing, China"
    email         : "hcp4715@gmail.com"
  - name          : "Kaiping Peng"
    affiliation   : "2"
  - name          : "Jie Sui"
    affiliation   : "3"

affiliation:
  - id            : "1"
    institution   : "Nanjing Normal University, 210024 Nanjing, China"
  - id            : "2"
    institution   : "Tsinghua University, 100084 Beijing, China"
  - id            : "3"
    institution   : "University of Aberdeen, Aberdeen, Scotland"

authornote: |
  Hu Chuan-Peng, School of Psychology, Nanjing Normal University, 210024 Nanjing, China.
  Kaiping Peng, Department of Psychology, Tsinghua University, 100084 Beijing, China.
  Jie Sui, School of Psychology, University of Aberdeen, Aberdeen, Scotland.

  Authors contriubtion: HCP, JS, & KP design the study, HCP collected the data, HCP analyzed the data and drafted the manuscript. All authors read and agreed upon the current version of the manuscripts.

abstract: |
 To navigate in a complex social world, our cognitive system are evolved to be sensitive to social information. Among all these social informaiton, morality related information is of special interest. On the one hand, paying attention to other's moral character profitable for ourselves. On the other hand, we need to maitain a moral self-view that fit the soical norm. Though behavioral effects of moral character and moral self-enhancement had been extensively studied in psychology of morality, social perception, and identity, whether the moral character related information can impact low-level perceptual process is unknown. In a series of experiments, we examined the effect of immediately acquired moral character information on perceptual matching. Participants first learned the association between moral character and visual cues (shapes), then performed a perceptual matching task. The results showed that shapes associated with positive moral character were prioritized, as compared to neutral or negative bad moral characters. This pattern was robust after changing the words for moral charachter or using diagnostic behavioral as an proxy of mroal character. Also, this patterns were robust when changing simultaneous presentation to sequential presentation. We then examined two approximate explanations for this effect: value-based prioritization or social-categorization based prioritization. We manipulated the identity of different moral character explicitly and found that the good moral character effect was strong when for the self-referential conditions but weak or non-exist for other-referential condition. We further tested the good-self based social categorization by presenting the identity or moral character information as task-irrelevant stimuli, so that we can distinguish between the unique good-self hypothesis and a more general good-person based social categorization hypothesis. We found that ....., these results suggested that participants are more senstive to the moral valence of self when the valence were task-irrelevant, but less sensitive to the identity of the morally good when the identity were task-irrelvant. These results added new evidence for the social vision and suggested the advantage of moral good depends on the self-relevant in perceptual decision-making task, instead of perspective free.
  
 <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "Perceptual decision-making, Self positivity bias, moral character"
wordcount         : "X"

bibliography      : 
  - r-references.bib
  - endnote.bib

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
figsintext        : no

documentclass     : "apa6"
classoption       : "man"
output            : 
  papaja::apa6_pdf:
    latex_engine  : xelatex

header-includes:
  - \usepackage{rotating}
  - \DeclareDelayedFloatFlavor{sidewaysfigure}{figure}
---
 <!-- This documents -->
 
```{r setup, include = FALSE}
#rm(list = ls())
source('Initial.r')

curDir = here::here()              # Get the current directory
figDir = here::here('figures')     # directory for figures.

# Seed for random number generation
set.seed(42)
options(tinytex.verbose = T) # debug the tex
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```
 <!-- What is the theoretic meaning of the series study? -->

# Introduction

 <!--[sentences in bracket are key ideas] -->

social vision --> moral vision --> two competing explanations (value-based vs. true-self-based) --> true-self is not perspective free but self-centered.

With limited cognitive resources, not all input information are processed equally. Visual stimuli, for example, are prioritized because for reasons: salient physical features, affective value or rewarding value [attention capture related papers]. To navigate in a social world, important social information shall also be prioritized. For example, self-relevant information. Beyond self-relevance, recent studies found that moral related information also prioritized (@brady_attentional_2020; @gantman_moral_2014). The center of morality is person (). Therefore it is not surprising that moral character information that associated with person having advantage in early information processing stage (@eiserbeck_visual_2020, @anderson_visual_2011). Studies used instantly acquired character related information to neutral faces and then tested these faces with various cognitive task, most studies found that neutral faces associated with negative social behavioral were prioritized as compared to neutral (and positive) (@anderson_visual_2011, @eiserbeck_visual_2020, but see @stein_no_2017), while other studies reported positive behavioral related faces were processed faster in attention (@shore_social_2013). 

Yet it is unclear what is exact mechanism underlying effect of moral character on perceptual process. Understanding the mechanism may help us to reconcile the seemingly conflicting results. So far, researchers reported that effect of moral character can happen between moral and non-moral, or between negative and neutral, or between positive and neutral. For each results, there can be an explanation. For example, the valence effect of moral character can be explained as a valence effect that resemble to the results in emotional stimuli, the negativity effect can then be explained by threatening effect, last but not least, the positivity effect can be explained by value-based information process, i.e., we are avoiding potential free-riders and approaching to potential cooperators. This value-based explanation had been used to explain previous results (e.g., @shore_social_2013). 

To clarify the effect and find a potential mechanism, we need first to find a robust effect that can be replicated. In the moral perceptual it is especially important because some of the experiments were not successfully replicated (see @stein_no_2017). After finding an stable effect, we could then explore the potential mechanisms. 

Here we reported a series experiments that first confirmed a robust effect of moral character in a laboratory setting, then examined two competing explanation for that robust effect. 

### Learning moral character instantly
One challenge when trying to study moral character's effect on perception lies in the difficulty to operationalize the "moral" part. Morality is defined by context. Whether a behavior should be judged as immoral depends on a number of factors such as intention, consequences [cushman, young], also depends on cultural and social norm [fiske, haidt]. These factors, when studied in laboratory settings, were usually carefully manipulated in verbal scenarios. However, when studying the perceptual or attentional effect of morality, long scenarios do not suit. 

Two approaches were used to solve this issue, both include using linguistic materials. The first approach combined moral words as materials and lexical decision task. For example @gantman_moral_2014, .....

Another approach is using the associative learning paradigm. ...

In moral psychology, however, there was a different view on why we judge other as good or bad: we doing so because we want to know who is us and who is other []. In other words, character is a signal of social categorization, indicating whether we can treat someone as extension of the self. 

Social associative learning task: "Even minimal behavioral information, such as a single sentence, is sufficient for robust positive or negative associations with a person face (Bliss-Moreau, Barrett, & Wright, 2008; Falvello, Vinson, Ferrari, & Todorov, 2015; Todorov & Olson, 2008). This demonstrates the readiness and ease with which such affective learning occurs – even in cases where the veracity of the information is unclear (Baum, Rabovsky, Rose, & Abdel Rahman, 2018)."

We designed a series of experiments to test these two hypotheses. 



[quotes about moral character]


People view a lot of news feed everyday, and the moral related information are more likely paid attention to and go viral on social media (@brady_attentional_2020). Most moral events are person-centered [@uhlmann_person-centered_2015], we are judging the moral character of individuals who involved in the moral event as "good" or "bad", and by condemning others or publicly showing our moral outrageous, we are signalling our own moral character, which is essential for us to living in the social world. 

If moral character is so important and serves as a signal for social categorization, it may also exert influence on how we perceive these information in the first place. To investigate the role of moral character in perception processing, we adopted the social associative learning task, where participants first paired geometric shapes with different moral characters, and then perform a perceptual matching task. Why this happen? Previous studies proposed that  moral content were prioritized because they are motivational relevant and provide us information about the social world. We argue that moral related information were prioritized because it's importance for social categorization.

[Moral character is the central theme in moral life]. People experience a substantial amount of moral events in everyday life [e.g., @hofmann_morality_2014]. When experiencing these events, it always involves judging the moral character of individuals involved in as "good" or "bad". Even when we are judging the behavioral as "right" or "wrong", we are implicitly judging the moral character of involved parties as "good" vs. "bad" [@uhlmann_person-centered_2015]. The importance of moral character was also supported by the extensive studies from person perception and social evaluation, where morality is a basic dimension for social evaluation [@goodwin_moral_2014; @goodwin_moral_2015; @abele_navigating_2020; @willis_first_2006] and the most important aspect to evaluate the continuity of identity [@strohminger_true_2017]. 

Given the importance of moral character in social life, it would not be a surprise if individual prioritize moral character related information, given the limited cognitive resources for processing the incoming information. Indeed, studies have shown that people can form a rapid judgment of others' moral character, "trustworthiness", by merely viewing faces of others. Beyond that, moral behaviors are deemed as the most diagnostic feature of a person (@ ; @). Recent theorists further integrated the moral judgment and moral self-view, proposed a person-centered account for moral psychology, which focused on the individuals in moral evaluation instead of acts [@uhlmann_person-centered_2015]. Under this framework, previous seemingly contradicting phenomenons can be explained. For example, whether people decide to expose an unethical behavior depends on how their relationship of the target [e.g., @waytz_whistleblowers_2013]. 

The importance of moral character also means that individual has a strong motivation to maintain a moral self-view [@ellemers_psychology_2019]. Studies found that people maintain a positive moral self-view even after dishonest behavior [@monin_dynamic_2009] and that people evaluate themselves as morally superior to others [@klein_maybe_2016; @tappin_illusion_2017]. 


To date, however, as @freeman_dynamic_2011 put it, studies in the perception of moral character didn't try to explain the perceptual process, rather, they are trying to explain the higher-order social cognitive processes that come after. Essentially, these studies are perception of moral character without perceptual process. Without knowledge of perceptual processes, we can not have a full picture of how moral character is processed in our cognition. As an increasing attention is paid to perceptual process underlying social cognition, it's clear that perceptual processes are strongly influenced by social factors, such as group-categorization, stereotype [see @bagnis_toward_2019; @xiao_perceiving_2016;@stolier_functional_2016]. Given the importance of moral character and that moral character related information has strong influence on learning and memory [@stanley_moral_2019; @carlson_motivated_2020], one might expect that moral character related information could also play a role in perceptual process.

To explore the perceptual process of moral character and the underlying mechanism, we conducted a series of experiments to explore (1) whether we can detect the influence of moral character information on perceptual decision-making in a reliable way, and (2) potential explanations for the effect. In the first four experiments, we found a robust effect of good-person prioritization in perceptual decision-making. Then, we explore the potential explanations and tested value-based prioritization versus good-self based prioritization (social-categorization [@turner_self_1994; @turner_rediscovering_1987]). These results suggested that people may categorize self and other based on moral character; in these categorizations, the core self, i.e., the good-self, is always prioritized.

## Perceptual process of moral character

[exp1a, b, c, and exp2]

[using associative learning task to study the moral character's influence on perception] Though it is theoretically possible that moral character related information may be prioritized in perceptual process, no empirical studies had directly explored this possibility. One difficulty of studying the perceptual process of moral character is that moral character is an inferred trait instead of observable feature. Usually, one needs more sensory input, e.g., behavior history, to infer moral character of a person. For example, @anderson_visual_2011 asked participant to first study the behavioral description of faces and then asked them to perform a perceptual detection task. They assumed that by learning the behavioral description of a person (represented by a face), participants can acquire the moral related information about faces, and the associations could then bias the perceptual processing of the faces (but see @stein_no_2017). One drawback of this approach is that participants may differ greatly when inferring the moral character of the person from behavioral descriptions, given that notion what is morality itself is varying across population [@henrich_weirdest_2010, @jones_which_2021] and those descriptions and faces may themselves are idiosyncratic, therefore, introduced additional variance to the targeted effect.

An alternative is to use abstract semantic concepts. Abstract concepts of moral character are used to describe and represent moral characters. These abstract concepts may be part of a dynamic network in which sensory cue, concrete behaviors and other information can activate/inhibit each other (e.g., aggressiveness) [@freeman_dynamic_2011; @amodio_social_2019]. If a concept of moral character (e.g., good person) is activated, it should be able to influence on the perceptual process of the visual cues through the dynamic network, especially when the perceptual decision-making is about the concept-cue association. In this case, abstract concepts of moral character may serve as signal of moral reputation (for others) or moral self-concept. Indeed, previous studies used the moral words and found that moral related information can be perceived faster [@gantman_moral_2014, but see, @firestone_enhanced_2015]. If moral character is an important in person perception, then, just as those other information such as races and stereotype [see @xiao_perceiving_2016], moral character related concepts also change the perceptual processes.

To investigate the above possibility, we used an associative learning paradigm to study how moral character concept change perceptual decision-making. In this paradigm, simple geometric shapes were paired with different words whose dominant meaning is describing the moral character of a person. Participants first learn the associations between shapes and words, e.g., triangle is a good-person. After formed direct associations between the labels of moral characters and visual cues, participants performed a perceptual matching task to judge whether the shape-word pair presented on the screen match the association they learned. This paradigm has been used in studying the perceptual process of self-concept, but had also proven useful in studying other concepts like social group [e.g., @enock_overlap_2020]. By using simple and morally neutral shapes, we controlled the variations caused by visual cues.

Our first question is, whether the words used the in the associative paradigm is really related to the moral character? This assumption is consistent with previous theories, especially the interactive dynamic theory. To validate that moral character concepts activated moral character as a social cue, we used four experiments to explore and validate the paradigm. The first experiment directly adopted associative paradigm and changed labels from "self", "friend", and "stranger" to "good-person", "neutral-person", and "bad-person". We further tried semantic labels that have more explicit moral meaning ("kind-person", "neutral-person", and "evil-person"). In the third experiments, as in @anderson_visual_2011, we asked participant to learn the association between three different diagnostic behavior and three different names, and then use the names as moral labels for the associative learning. Finally, we also tested that simultaneously present shape-word pair and sequentially present word and shape didn't change the pattern. All of these four experiments showed a consistent pattern of effect, that is, the visual cues that associated with positive moral character were prioritized. 

## Morality as a social-categorization?

[possible explanations: person-based self-categorization vs. stimuli-based valence] The robust pattern from the first four experiments revealed a novel pattern that needs an explanation. It's novel because it's contradict with the "negative is stronger than positive" hypothesis in social psychology [@baumeister_bad_2001]. There are two major alternatives. One possible explanation is the value-based attention, which suggested that valuable stimuli is prioritized in our low-level cognitive processes. Because positive moral character is potentially rewarding, e.g., potential cooperators, it is valuable to individuals and therefore being prioritized. Most empirical evidence for value-based attention are from experiments used monetary reward. However, the monetary reward might be different greatly from the morality in social setting. So far, only a few empirical studies supported the value-based attention in social evaluation. @eiserbeck_visual_2020 and @shore_social_2013 found that neutral faces, after associated with trustworthy behavioral description or trustworthy interaction history, attracted attention more than untrustworthy faces, probably because trustworthy faces are more likely to be the collaborative partners subsequent tasks, which will bring reward. Applying this explanation to the current setting need a further assumption that  participants automatically view the moral character related information as self-relevant objects. Only based on the objectified stimuli that we evaluate their value (rewarding or threatening) to us [@juechems_where_2019; @reicher_perception_2016]. 

Another possibility is that we will perceive those moral character not as objects but as person, and automatic categorize whether they are in-group or out-group, instead of calculating their value to us. This account assumed that moral character served as a way to categorize other. In the first four experiments' situation, the identity of the moral character is ambiguous, participants may automatically categorize morally good people as in-group (as an extension of themselves) and therefore preferentially processed these information. 

However, the above four experiments could not distinguish between these two possibilities, because the concept "good-person" can both be rewarding and be categorized as in-group member, and previous studies using associative learning paradigm revealed that both rewarding stimuli [e.g., @Sui_2012_JEPHPP] and in-group information [@enock_overlap_2020] are prioritized.  

[Distinguish two explanations by make self salient, exp3a, 3b, 6b] Though both two the value-based attention and moral-based categorization accounts can explain the positivity effect found in first four experiments (i.e., prioritization of "good-person", but not "neutral person" and "bad person"), they have different prediction if the experimental design include both identity and moral valence where the valence (good, bad, and neutral) conditions can describe both self and other. In this case the identity become salient and participants are less likely to spontaneously identify a good-other as the extension of self, but the value of good-person still exists. Actually, the rewarding value of good-other might be even stronger than good-self because the former indicate potential cooperation and material rewards, but the latter merely confirmed one's personal belief. This means that the social categorization theory predicts participants prioritize good-self but not good-other, while reward-based attention theory predicts participants are both prioritized, or maybe good-other are even more prioritized. Also, as in @Hu_2020_GoodSelf, people may also only identify with good-self instead of bad self. That is, people will show a unique pattern of self-identification: only good-self is identified as "self" while all the others categories were excluded.

We introduced identity (self vs. other) as an addition independent variable in exp 3a, 3b, and 6b. Now the moral valence is orthogonal to the identity. We found that (1) good-self is always faster than neutral-self and bad-self, but good-other only have weak to null advantage to neutral-other and bad-other. which mean the social categorization is self-centered. (2) good-self's advantage over good other only occur when self- and other- were in the same task. i.e. the relative advantage is competition based instead of absolute. These three experiments suggest that people more like to view the moral character stimuli as person and categorize good-self as an unique category against all others. A three-level Bayesian generalized linear mixed effect model showed that there was no effect of valence when the identity was other. This results showed that value-based attention was not likely the mechanism behind the pattern we observed in first four experiments. However, it is still unclear Why good-self was prioritized. Besides the social-categorization explanation, it's also possible that good self is so unique that it is prioritized in all possible situation and therefore is not social categorization *per se*. 

[what we care? valence of the self exp4a or identity of the good exp4b?] We go further to disentangle the good-self complex: is it because the special role of good-self or because of social categorization. We designed two complementary experiments. in experiment 4a, participants only learned the association between self and other, the words "good-person", "neutral person", and "bad person" were presented as task-irrelevant stimuli, while in experiment 4b, participants learned the associations between "good-person", "neutral-person", and "bad-person", and the "self" and "other" were presented as task-irrelevant stimuli. These two experiment can be used to distinguish the "good-self" as anchor account and the "good-self-based social categorization" account. If good-self as an anchor is true, then, in both experiment, good-self will show advantage over all other stimuli. More specifically, in experiment 4a, where only the self-relevance is task-relevant, there will be advantage for good as task-irrelevant condition than the other two self conditions; in experiment 4b, in the good condition, there will be an advantage for self as task-irrelevant condition over other as task-irrelevant condition. If good-self-based social categorization if true, then, the prioritization effect will depends on whether the stimuli can be categorized as the same group of good-self. More specifically, in experiment 4a, there will be good-as-task-irrelevant stimuli than other condition in self conditions, this prediction is the same as the "good-self as anchor" account; however, for experiment 4b, there will be no self-as-task-irrelevant stimuli than other-as-task-irrelevant condition.

[Good self in self-reported data] As an exploration, we also collected participants' self-reported psychological distance between self and good-person, bad-person, and neutral-person, moral identity, moral self-image, and self-esteem. All these data are available [see @Liu_2020_JOPD]. We explored the correlation between self-reported distance and these questionnaires as well as the questionnaires and behavioral data. However, given that the correlation between self-reported score and behavioral data has low correlation [@dang_why_2020], we didn't expect a high correlation between these self-reported measures and the behavioral data.

[whether categorize self as positive is not limited to morality] Finally, we explored the pattern is generalized to all positive traits or only to morality. We found that self-categorization is not limited to morality, but a special case of categorization in perpetual processing. 

Key concepts and discussing points:

**Self-categories** are cognitive groupings of self and some class of stimuli as identical or different from some other class. [Turner et al.]

**Personal identity** refers to self-categories that define the individual as a unique person in terms of his or her individual differences from other (in-group) persons.

**Social identity** refers to the shared social categorical self ("us" vs. "them").

**Variable self**: Who we are, how we see ourselves, how we define our relations to others (indeed whether they are construed as ‘other’ or as part of the extended 'we' self) is different in different settings. 

**Identification**: the degree to which an individual feels connected to an ingroup or includes the ingroup in his or her self-concept. (self is not bad; )

Morality as a way for social-categorization [@mchugh_moral_2019]? People are more likely to identify themselves with trustworthy faces [@verosky_differential_2010] (trustworthy faces has longer RTs).

What is the relation between morally good and self in a semantic network (attractor network) (Freeman & Ambady, 2011)? The psychological essentialism account proposed that the moral good self is perspective independent, i.e., there is a moral good self in all. This perspective free effect is not exist in our effect.

How to deal with the *variable self* (self-categorization theory) vs. *core/true/authentic self* vs. *self-enhancement*

**Limitations**:
The perceptual decision-making will show certain pattern under certain task demand. In our case, it's the forced, speed, two-option choice task.

in experiment 4a and 4b, we didn't have a baseline condition where there is no word inside the shape?

# Disclosures
We reported all the measurements, analyses, and results in all the experiments in the current study. Participants whose overall accuracy lower than 60% were excluded from analysis. Also, the accurate responses with less than 200ms reaction times were excluded from the analysis.  

All the experiments reported were not pre-registered. Most experiments (1a ~ 6b, except experiment 3b) reported in the current study were first finished between 2014 to 2016 in Tsinghua University, Beijing, China. Participants in these experiments were recruited in the local community. To increase the sample size of experiments to 50 or more [@Simmons_2013_life], we recruited additional participants in Wenzhou University, Wenzhou, China in 2017 for experiment 1a, 1b, 4a, and 4b. Experiment 3b was finished in Wenzhou University in 2017. To have a better estimation of the effect size, we included the data from two experiments (experiment 7a, 7b) that were reported in @Hu_2020_GoodSelf (See Table S1 for overview of these experiments). 

All participant received informed consent and compensated for their time. These experiments were approved by the ethic board in the Department of Tsinghua University. 

 <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

```{r loadingData,echo=FALSE,results='hide'}
load("AllData.RData")

### expclude the repeated subj from the raw data

# No repeating subj
df1a.v_meta <- df1a.v

# No repeating subj
df1b.v_meta <- df1b.v

# exclude participant from exp 1a
df1c.v_meta <- df1c.v %>% dplyr::filter(!Subject %in% c(1206, 1207, 1208, 1210))

# exclude participant from exp 1a
df2.v_meta <- df2.v %>% dplyr::filter(Subject > 2000)    

# exclude participants from ex1b, 1c, and 2
df3a.v_meta <- df3a.v %>% dplyr::filter(!Subject %in% c(3013, 3012, 3043, 3046)) 

# No repeating subj
df3b.v_meta <- df3b.v

# No repeating subj
df4a.v_meta <- df4a.v

# exclude participants from ex1b, 1c, and 2
df4b.v_meta <- df4b.v %>% dplyr::filter(!Subject %in% c(4210, 4202, 4201))   

# exclude participants from ex1b, 1c, and 2
df5.v_meta <- df5.v %>% dplyr::filter(!Subject %in% c(5201))   

# exclude participants from ex1b, 1c, and 2
df6a.v_meta <- df6a.v %>% dplyr::filter(!Subject %in% c(6118,6119,6122,6123,6131))   

# exclude participants from ex1b, 1c, and 2
df6b.v_meta <- df6b_d1.v %>% dplyr::filter(!Subject %in% c(6217))   

# exclude participants from ex1b, 1c, and 2
df7a.v_meta <- df7a_m.v %>% dplyr::filter(!Subject %in% c(7020))   

# No repeating subj
df7b.v_meta <- df7b_m.v


df1a.v_meta$ExpID <- 'Exp1a'
df1b.v_meta$ExpID <- 'Exp1b'
df1c.v_meta$ExpID <- 'Exp1c'
df2.v_meta$ExpID  <- 'Exp2'
df3a.v_meta$ExpID <- 'Exp3a'
df3b.v_meta$ExpID <- 'Exp3b'
df4a.v_meta$ExpID <- 'Exp4a'
df4b.v_meta$ExpID <- 'Exp4b'
df5.v_meta$ExpID  <- 'Exp5'
df6a.v_meta$ExpID <- 'Exp6a'
df6b.v_meta$ExpID <- 'Exp6b'
df7a.v_meta$ExpID <- 'Exp7a'
df7b.v_meta$ExpID <- 'Exp7b'
```

```{r define_funs, echo=FALSE, results='hide'}
# define a function to run the sdt GLMM for all exp with Matchness * Valence design
# for 1a, 1b, 1c, 2, 6a
fun_sdt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
  brms::brm(saymatch ~ 0 + Valence + ismatch:Valence + 
              (0 + Valence + ismatch:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

fun_plot_sdt_val <- function(m_sdt) {
    # extract c
    tmp_c <- m_sdt %>% 
      tidybayes::gather_draws(b_ValenceBad, b_ValenceNeutral, b_ValenceGood) %>%
      dplyr::rename(Valence = .variable, sdt_c = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # dprime
    tmp_d <- m_sdt %>% 
      tidybayes::gather_draws(`b_ValenceBad:ismatch`, `b_ValenceNeutral:ismatch`, 
                              `b_ValenceGood:ismatch`) %>%
      dplyr::rename(Valence = .variable, sdt_d = .value) %>% dplyr::ungroup() %>%
      dplyr::mutate(Valence = gsub("b_", "", Valence)) %>%
      dplyr::mutate(Valence = ifelse(stringr::str_detect(Valence, 'Bad'), 'Bad',
                                     ifelse(stringr::str_detect(Valence, 'Good'), 'Good', 'Neutral')))
    
    # plot summaries with densities
    p_sdt_d_sum <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "sensitivity (d')", y = 'Posterior') +
      theme_classic()
    
    p_sdt_c_sum <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "criteria (c)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_sdt_d <- tmp_d %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_d, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_d, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "sensitivity (d')", y = 'Comparison') +
      theme_classic()
    
    p_sdt_c <- tmp_c %>%
      dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      tidybayes::compare_levels(sdt_c, by = Valence) %>%
      ggplot2::ggplot(aes(x = sdt_c, y = Valence, fill = stat(x > 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(x = "criteria (c)", y = 'Comparison') +
      theme_classic()
    
    return(list(p_sdt_d_sum, p_sdt_c_sum, p_sdt_d, p_sdt_c))
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
    brms::brm(RT_sec ~ ismatch*Valence + (ismatch*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

fun_plot_rt_val <- function(m_rt) {
    tmp_rt <- m_rt %>% 
      tidybayes::spread_draws(b_Intercept, b_ValenceBad, b_ValenceGood, 
                              b_ismatch,   `b_ValenceBad:ismatch`, `b_ValenceGood:ismatch`) %>%
      dplyr::mutate(Neut_MM = b_Intercept,
                    Bad_MM = Neut_MM + b_ValenceBad,
                    Good_MM = Neut_MM + b_ValenceGood,
                    Neut_M = Neut_MM + b_ismatch,
                    Bad_M = Neut_MM + b_ismatch + `b_ValenceBad:ismatch`,
                    Good_M = Neut_MM + b_ismatch + `b_ValenceGood:ismatch`) %>%
      dplyr::select(-contains('b_')) %>%
      tidyr::pivot_longer(cols = Neut_MM:Good_M,
                          names_to = 'cond',
                          values_to = 'logRT') %>%
      dplyr::mutate(RT = exp(logRT)*1000,
                    Matchness = dplyr::case_when(grepl("_MM$", cond) ~ "Mismatch",
                                                 grepl("_M$", .variable) ~ "Match"),
                    Valence = dplyr::case_when(grepl("Neut", cond) ~ "Neutral",
                                               grepl("Bad", cond) ~ "Bad",
                                               grepl("Good", cond) ~ "Good")
                    # Matchness = dplyr::case_when(cond == 'Neut_MM' | cond == 'Bad_MM' | cond == 'Good_MM' ~ 'Mismatch',
                    #                              cond == 'Neut_M'  | cond == 'Bad_M'  | cond == 'Good_M' ~ 'Match'),
                    # Valence = dplyr::case_when(cond == 'Neut_MM' | cond == 'Neut_M' ~ 'Neutral',
                    #                            cond == 'Bad_MM'  | cond == 'Bad_M'  ~ 'Bad', 
                    #                            cond == 'Good_MM' | cond == 'Good_M' ~ 'Good')
                    )
    p_exp1b_rt_m_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(x = "RTs (Matching, ms)", y = 'Posterior') +
      theme_classic()
    p_exp1b_rt_mm_sum <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Bad', 'Neutral', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      ggplot2::ggplot(aes(x = RT, y = Valence)) +
      tidybayes::stat_halfeyeh() + 
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Posterior') +
      theme_classic()
    
    # plot comparison
    p_exp1b_rt_m <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Match') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'C', x = "RTs (Matching, ms)", y = 'Comparison') +
      theme_classic()
    p_exp1b_rt_mm <- tmp_rt %>% dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good'))) %>%
      dplyr::filter(Matchness == 'Mismatch') %>%
      tidybayes::compare_levels(RT, by = Valence) %>%
      ggplot2::ggplot(aes(x = RT, y = Valence, fill = stat(x < 0))) +
      tidybayes::stat_halfeyeh() + 
      geom_vline(xintercept =0, linetype = "dashed") +
      scale_fill_manual(values = c("gray80", "skyblue")) +
      labs(tag = 'D', x = "RTs (Mismatching, ms)", y = 'Comparison') +
      theme_classic()
    return(list(p_exp1b_rt_m_sum, p_exp1b_rt_mm_sum, p_exp1b_rt_m, p_exp1b_rt_mm))
}

fun_sdt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_sdt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  
  m <- df %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
              (0 + Identity:Valence + ismatch:Identity:Valence | Subject),
            family = bernoulli(link="probit"),
            data = .,
            control = list(adapt_delta = .99),
            iter = 4000,
            thin = 2,
            cores = parallel::detectCores(),
            file = here::here(m_name))
  return(m)
}

# define a function to run the RT GLMM for all exp with Matchness * Valence design
fun_rt_val_id <- function(exp_name) {
  df_name <- paste('df', exp_name, '.v', sep = '')
  m_name <- paste("glmmModels/exp", exp_name, "_rt_m1_DummyCode", sep = '')
  df <- get(df_name)  # get the data by string
  m <- df %>%
    dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
    dplyr::filter(ACC == 1) %>%
    dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                  Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                  Identity = factor(Identity, levels=c('Self', 'Other'))) %>%
    brms::brm(RT_sec ~ ismatch*Identity*Valence + (ismatch*Identity*Valence | Subject),
              family = shifted_lognormal(),
              data = ., control = list(adapt_delta = .99),
              iter = 4000,
              thin = 2,
              cores = parallel::detectCores(),
              file = here::here(m_name))
  return(m)
}

```

  <!-- A general method part describing experimental design and data analysis -->
```{r child = "general_method.rmd"}
```

# Part 1: Perceptual processing moral character related information
In this part, we report results from five experiments that tested whether an associative learning task, including 192 participants. Note that for both experiment 1a and 1b, there were two independent samples with different equipment, trials numbers and testing situation. Therefore, we modeled them as independent samples.  These five experiments revealed a robust effect of moral character on perceptual matching task. 


```{r remove non-meta data, eval = FALSE, echo=FALSE, results='hide', warning=FALSE}
# remove all unnecessary variables
var_list <- c('df1a.v_meta', 'df1b.v_meta', 'df1c.v_meta', 'df2.v_meta', 'df3a.v_meta', 'df3b.v_meta',
              'df4a.v_meta', 'df4b.v_meta', 'df5.v_meta', 'df6a.v_meta', 'df6b.v_meta', 'df7a.v_meta', 'df7b.v_meta',
              'apatheme','exp_table', 'curDir', 'figDir')
rm(list=ls()[! ls() %in% var_list])
```

```{r prepare data for first meta, echo=FALSE, results='hide', warning=FALSE}
### try meta-analysis 1a, 1b, 1c, 2, 5 and 6a
selected_columns <- c('ExpID', 'Site', 'Subject','Age', 'Sex', 'Matchness','Valence', 'RESP', 'ACC','RT')
df_moral <- dplyr::bind_rows(df1a.v_meta[selected_columns],
                             df1b.v_meta[selected_columns],
                             df1c.v_meta[selected_columns],
                             df2.v_meta[selected_columns],
                             df5.v_meta[selected_columns],
                             df6a.v_meta[selected_columns]) %>%
  dplyr::mutate(ExpID_new = paste(ExpID, Site, sep = "_")) %>%
  dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')))

df_moral_subj <- df_moral %>%
  dplyr::group_by(ExpID_new, Site) %>%
  dplyr::summarize(N = n_distinct(Subject),
                   N_trial = length(Subject),
                   Exp_conds = 6,
                   trial_per_cond = round((length(Subject)/6)/N, 0))

df_moral <- df_moral %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0)) %>%
  dplyr::select(ExpID_new, Subject, Valence, Matchness, RESP, ACC, RT, ismatch, saymatch) %>%
  dplyr::mutate(ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# # plot the nested structure of the data
# with(df_moral, table(Subject, ExpID_new)) %>%
#   image(
#     col = grey.colors(80, start = 1, end = 0), 
#     axes = TRUE, 
#     xlab = "Subject", 
#     ylab = "ExpID"
#   )

```

```{r first meta sdt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for SDT, didn't specify the prior; dummy coding
# about 20 hours to finish this sampling using ntel® Xeon(R) CPU E3-1505M v5 @ 2.80GHz × 8 machine.
# 87432.5 = 24.3 hours
sdt_val_m1 <- brms::brm(saymatch ~ 0 + Valence + Valence:ismatch + 
                         (0 + Valence + Valence:ismatch | ExpID_new) + 
                         (0 + Valence + Valence:ismatch  | ExpID_new:Subject),
                       family = bernoulli(link="probit"),
                       data = df_moral,
                       control = list(adapt_delta = .95),
                       cores = parallel::detectCores(),
                       backend = 'cmdstanr',  # with cmdstanr
                       file = here::here("glmmModels/sdt_val_DummyCode_3_level"))

summary(sdt_val_m1)
# stancode(sdt_val_m1)

# plot(hypothesis(sdt_val_m1, "ValenceBad:ismatch > ValenceNeutral:ismatch"))
# 
# plot(hypothesis(sdt_val_m1, "ValenceGood:ismatch > ValenceNeutral:ismatch"))

# combined with emmeans, no longer used
# sdt_val_m1_p <- sdt_val_m1 %>%
#   emmeans::emmeans( ~ ismatch | Valence) %>%
#   tidybayes::gather_emmeans_draws() %>%
#   dplyr::filter(ismatch == 'd prime') %>%
#   ggplot2::ggplot(aes(x = Valence, y = .value)) +
#   tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
#   stat_summary(aes(group = NA), fun = mean, geom = "line") +
#   ylab(expression(paste("Sensitivity ",italic("d'"), sep = ' '))) +
#   facet_grid(cols = vars(ismatch), scales = "free_y") +
#   theme_classic() + 
#   theme(axis.title.x = element_blank())

# plot the population level parameter (d prime)
sdt_val_m1_p <- sdt_val_m1 %>%
        # get the traces of population level parameters
        tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
        # create two columns for two independent factors.
        dplyr::mutate(Valence = dplyr::case_when(
                grepl("ValenceBad", .variable) ~ "Bad",
                grepl("ValenceNeutral", .variable) ~ "Neutral",
                grepl("ValenceGodd", .variable) ~ "Good"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "d prime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('d prime', 'criterion')),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))
          ) %>%
  # select only d prime
  dplyr::filter(params == 'd prime') %>%
  ggplot2::ggplot(aes(x = Valence, y = .value)) +
  tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
  stat_summary(aes(group = NA), fun = mean, geom = "line") +
  ylab(expression(paste("Sensitivity ", italic("d'"), sep = ' '))) +
  # xlab("Valence") +
  #facet_grid(cols = vars(params), scales = "free_y") +
  theme_classic() # + 
  # theme(axis.title.x = element_blank())

#### plot both overall parameters and experimental levels.
# # Get the variables in the model
# var_name_m1 <- tidybayes::get_variables(sdt_val_m1)

df_m1_post_sdt_exp <- sdt_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

pop_mean <- sdt_val_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_sdt_m1_pop <- sdt_val_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_m1_post_sdt_exp_update <- merge(df_sdt_m1_pop, df_m1_post_sdt_exp, by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population level value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_plot_sdt <- df_sdt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_m1_post_sdt_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition), # reverse the order because the plot function auto reverse.
                term = dplyr::case_when((term == "ValenceBad") ~ "c_Bad",
                                    (term == "ValenceNeutral") ~ "c_Neutral",
                                    (term == "ValenceGood") ~ "c_Good",
                                    (term == "ValenceBad:ismatch") ~ "dprime_Bad",
                                    (term == "ValenceNeutral:ismatch") ~ "dprime_Neutral",
                                    (term == "ValenceGood:ismatch") ~ "dprime_Good"),
                term = factor(term, levels = c("c_Bad", "c_Neutral", "c_Good",
                                               "dprime_Bad", "dprime_Neutral", "dprime_Good"))) 

df_m1_plot_sdt_diff <- df_m1_plot_sdt %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_c = c_Good - c_Bad,                           # calculate the differences between conditions
                diff_GN_c = c_Good - c_Neutral,
                diff_BN_c = c_Bad - c_Neutral,
                diff_GB_dprm = dprime_Good - dprime_Bad,
                diff_GN_dprm = dprime_Good - dprime_Neutral,
                diff_BN_dprm = dprime_Bad - dprime_Neutral) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_c,diff_GN_c, diff_BN_c,
               diff_GB_dprm, diff_GN_dprm, diff_BN_dprm) %>%
  tidyr::pivot_longer(cols = diff_GB_c:diff_BN_dprm, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_c','diff_GN_c', 'diff_BN_c',
                                                         'diff_GB_dprm', 'diff_GN_dprm', 'diff_BN_dprm')))

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines_df_m1_sdt <- df_m1_plot_sdt %>% 
        tidyr::separate(term, c('params', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_dprime1 <- df_m1_plot_sdt %>%
        tidyr::separate(term, c('params', 'Valence')) %>%
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::rename(Experiments = condition) %>%
        # dplyr::mutate(Experiments = factor(Experiments, levels = c("Exp1b_WZU", "Exp5_THU", "Exp1a_THU", 
        #                                                            "Exp1b_THU", "Exp1c_THU", "Exp2_THU" , 
        #                                                            "Exp1a_WZU",  "Exp6a_THU","Overall")),
        #               Experiments = fct_rev(Experiments)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = vlines_df_m1_sdt, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of '~italic(d)~' prime')) + 
        scale_colour_brewer(palette = "Dark2") +
        scale_fill_brewer(palette = "Dark2") +
        theme_apa()

# plot the posterior of the difference between d prime
p_dprime1_diff <- df_m1_plot_sdt_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm')) %>%
        dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        xlab(expression(paste("Effect of valence on ", italic("d"), "prime", sep = ' '))) + 
        facet_wrap( ~ term_diff, # scales = "free_y",
                    nrow = 1,
                    labeller = label_parsed)

# # plot the posterior of difference between c, supplementary figure
# df_m1_plot_sdt_diff %>%
#   dplyr::filter(str_detect(term_diff, '_c')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
#   tidybayes::stat_halfeye() +
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c('gray80', 'skyblue')) +
#   xlab("Valence effect on criterion in SDT") +
#   facet_wrap( ~ term_diff, # scales = "free_y",
#                nrow = 1,
#                labeller = label_parsed)

# posterior predictive check
#pp_check(sdt_val_m1)
#pp_sdt_val_m1 <- 
#  brms::pp_check(sdt_val_m1, nsamples = 1e2) + 
#  ggtitle("PPC sdt_val_m1") +
#  theme_bw (base_size = 10) + 
#  theme(legend.position = "none") +
#  xlim(-0.5, 1.5)
```

```{r first meta rt, echo=FALSE, results='hide', warning=FALSE}
# have a look at a few participants' data
# set.seed(123)
# random_sub <- sample(unique(df_moral$Subject), 10)
# random_sub

# # plot the distribution of 10 randomly selected participants
# df_moral %>%
#   dplyr::mutate(RT_sec = RT/1000) %>%  # log RT in seconds
#   dplyr::filter(ACC == 1) %>%          # only correct trials
#   dplyr::filter(Subject %in% random_sub) %>%
#   dplyr::mutate(cond = paste(Matchness, Valence, sep = "_"),
#                 RT_log = log(RT_sec))%>%
#   ggplot2::ggplot(., aes(x=RT_log)) + 
#   geom_histogram(aes(fill=cond), alpha=0.5, bins=60) + 
#   facet_wrap(~Subject, nrow = 2) +  # One panel per id
#   coord_cartesian(xlim=c(-2, 1))

# fit a three-level hierarchical model for RT, didn't specify the prior, shifted_lognormal, effective coding
RT_val_m1 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%         # only correct trials
  brms::brm(RT_sec ~ Valence*ismatch_num + 
              (Valence*ismatch_num | ExpID_new) +   
              (Valence*ismatch_num | ExpID_new:Subject),
            family=shifted_lognormal(),
            data = .,
            control = list(adapt_delta = .95),
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_val_EffectCode_3_level"))

# plot(RT_val_m1, "b_")
summary(RT_val_m1)  # ndt = 0 there fore, we used lognormal.
# pp_check(RT_val_m1)

# Will try dummy coding later, but the running time is long: Total execution time: 124845.8 seconds = 34.7 hours
# RT_val_m1 <- df_moral %>%
#   dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
#   dplyr::filter(ACC == 1) %>%         # only correct trials
#   brms::brm(RT_sec ~ Valence*ismatch +
#               (Valence*ismatch | ExpID_new) +
#               (Valence*ismatch  | ExpID_new:Subject),
#             family=lognormal(),
#             data = .,
#             control = list(adapt_delta = .95),
#             cores = parallel::detectCores(),
#             backend = 'cmdstanr',  # with cmdstanr
#             file = here::here("glmmModels/RT_val_DummyCode_3_level"))
# 
# summary(RT_val_m1)

#Population-Level Effects: 
#                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
#Intercept                  -0.40      0.06    -0.52    -0.27 1.01      837     1301  # baseline: mismatch:neutral
#ValenceBad                  0. 01      0.00     0.00     0.02 1.00     1752     2540  # mismatch:bad - mismatch:neutral = 0.01
#ValenceGood                -0.03      0.00    -0.04    -0.02 1.00     1237     2219  # mismatch:Good - mismatch:neutral = -0.03
#ismatch_num                -0.07      0.01    -0.09    -0.06 1.00     1638     1957  # match:neutral - mismatch:neutral = -0.07
#ValenceBad:ismatch_num      0.02      0.01     0.00     0.04 1.00     1597     2380  # match:bad - ValenceBad -ismatch_num = 0.02
#ValenceGood:ismatch_num    -0.05      0.01    -0.07    -0.03 1.00     1424     1775  # match:good - ValenceGood- ismatch_num = -0.05

# Mismatch:Neutral - Intercept = -0.4
# Mismatch:Bad     - Intercept  + ValenceBad = -0.4 + 0.01 = -0.39
# Mismatch:Good    - Intercept  + ValenceGood = -0.4 - 0.03 = -0.43
# Match: Neutral   - Intercept  + ismatch_num = -0.4 - 0.07 = -0.47
# Match: Bad       - Intercept  + ismatch_num + ValenceBad+ ValenceBad:ismatch_num = -0.4 + 0.01 + 0.02 =  -0.37 
# Match: Good      - Intercept  + ismatch_num + ValenceGood+ ValenceGood:ismatch_num = -0.4 + (-0.03) + (-0.05) = -0.48

# Get the variables in the model 1
# RT_var_name_m1 <- tidybayes::get_variables(RT_val_m1)

df_m1_post_rt_exp <- RT_val_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_rt_m1_pop_mean <- RT_val_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_rt_m1_pop <- RT_val_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_m1_post_rt_exp_update <- merge(df_rt_m1_pop, df_m1_post_rt_exp, 
# rt_post_tmp <- merge(rt_pop_post, df_m1_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m1_plot_rt <- df_rt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>% # chagne the `pop_mean` as `value` for data frame merge
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_m1_post_rt_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(Neutral_NM = Intercept,               # calculate the differences between coditions
                Bad_NM = Intercept  + ValenceBad,
                Good_NM = Intercept  + ValenceGood ,
                Neutral_M = Intercept  + ismatch_num,
                Bad_M = Intercept  + ismatch_num + ValenceBad + `ValenceBad:ismatch_num`,
                Good_M = Intercept  + ismatch_num + ValenceGood+ `ValenceGood:ismatch_num`) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               Neutral_NM, Bad_NM, Good_NM,
               Neutral_M, Bad_M, Good_M) %>%
  tidyr::pivot_longer(cols = Neutral_NM:Good_M, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('Good_NM', 'Neutral_NM', 'Bad_NM',
                                               'Good_M',  'Neutral_M',  'Bad_M')),
                value = exp(value),
                value = value * 1000) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
vlines <- df_m1_plot_rt %>% 
        tidyr::separate(term, c('Valence', 'Match')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_rt1 <- df_m1_plot_rt %>%
        tidyr::separate(term, c('Valence', 'Match')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::rename(Experiments = condition) %>%
        # dplyr::mutate(Experiments = factor(Experiments, levels = c("Exp1b_WZU", "Exp5_THU", "Exp1a_THU", 
        #                                                            "Exp1b_THU", "Exp1c_THU", "Exp2_THU" , 
        #                                                            "Exp1a_WZU",  "Exp6a_THU","Overall")),
        #               Experiments = fct_rev(Experiments)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of reaction times')) + 
        scale_colour_brewer(palette = "Dark2") +
        scale_fill_brewer(palette = "Dark2") +
        theme_apa()


df_m1_plot_rt_diff <- df_m1_plot_rt %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = Good_NM - Bad_NM,               # calculate the differences between conditions
                diff_GN_NM = Good_NM - Neutral_NM,
                diff_BN_NM = Bad_NM - Neutral_NM,
                diff_GB_M = Good_M - Bad_M, 
                diff_GN_M = Good_M - Neutral_M,
                diff_BN_M = Bad_M - Neutral_M,) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))
# 
# df_m1_rt_plot %>% 
#   dplyr::group_by(condition, term_diff, .chain) %>%
#   dplyr::tally()

# df_m1_rt_mean <- df_m1_rt_plot %>%
#   #tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
#   #                        `b_ismatch_num`, `b_ValenceBad:ismatch_num`, 
#   #                        `b_ValenceGood:ismatch_num`) %>%
#   group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
#   tidybayes::mean_hdci(value)  # get the high density continuous intervals

# plot the posterior of mismatch
# df_m1_plot_rt_diff  %>%
#   dplyr::filter(str_detect(term_diff, '_NM')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
#   tidybayes::stat_halfeye() +
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c('gray80', 'skyblue')) + 
#   xlab("Effect (differences) of valence on RT (Mismatch trials)")+
#   facet_wrap( ~ term_diff, 
#               # scales = "free_y", 
#               nrow = 1,
#               labeller = label_parsed)

# plot the posterior of matching trials
p_rt1_diff <- df_m1_plot_rt_diff %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeye() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  # scale_fill_manual(values = c('gray80', 'skyblue')) +
  scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
  xlab("Effect of valence on RT (Match trials)") +
  facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)
```

  <!-- plot all graphs form the first part together -->
  
```{r plot-bayes-meta-1, fig.cap="Effect of moral valence on RT and d'", fig.height=9, fig.width=15, warning=FALSE}
library(patchwork)
p_rt1 + p_dprime1 +
        p_rt1_diff + p_dprime1_diff + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 2, byrow = TRUE, guides = 'collect')

# p <- p_rt1 + p_dprime1 + plot_annotation(tag_levels = 'A') + plot_layout(guides = "collect") 

#  ggsave('part1_plot_posterior.png', p, width = 15, height = 7.5)
```

For the *d* prime, we found robust effect of moral valence. Shapes associated with positive moral valence ("good person", "kind person" or a name associated with morally good behavioral history) has higher sensitivity (mean = , 95% HDI = ) than shapes associated with neutral condition (mean = , 95% HDI = ), but we did not find differences between shapes associated with negative moral label (mean = , 95% HDI = ) and neutral condition.

For the reaction times, we also found robust effect of moral valence. Shapes associated with positive moral valence has faster responses (mean = , 95% HDI = ) than shapes associated with neutral condition (mean = , 95% HDI = ). We also found that the responses to shapes associated with negative moral valence (mean = , 95% HDI = ) were slower as compared to the neutral condition. See Figure \@ref(fig:plot-bayes-meta-1).

```{r model comp for rt, eval = FALSE, echo=FALSE, results='hide' }
#### model copmarison etc, will be in supplementary materials
# 
# log normal distribution, dummy coding
RT_val_m2 <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m2"))
summary(RT_val_m2)

# log normal distribution, with truncated distribution, , dummy coding
RT_val_m3_trunc <- df_moral %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%
  brms::brm(RT_sec|trunc(lb = 0.2, ub = 1.1) ~ Valence*ismatch + 
              (Valence*ismatch | ExpID_new) +   
              (Valence*ismatch | ExpID_new:Subject),
            family=lognormal(),
            data = .,
            control = list(adapt_delta = .98),
            cores = parallel::detectCores(),
            file = here::here("glmmModels/RT_val_EffectCode_3_level_m3_trunc"))
summary(RT_val_m3_trunc)
pp_check(RT_val_m3_trunc)
#plot(RT_val_m3_trunc, "b_")

# compare three models
loo(RT_val_m1, RT_val_m2, RT_val_m3_trunc) # takes about XX mins
bayes_factor(RT_val_m1,RT_val_m2)
# Monte Carlo SE of elpd_loo is 0.4.

#All Pareto k estimates are good (k < 0.5).
#See help('pareto-k-diagnostic') for details.

#Model comparisons:
#                elpd_diff se_diff
#RT_val_m1          0.0       0.0 
#RT_val_m2         -5.6       3.3 
#RT_val_m3_trunc -590.6      34.8 

# Get the variables in the model 3
RT_var_name_m3 <- tidybayes::get_variables(RT_val_m3_trunc)

df_m3_post_rt_exp <- RT_val_m3_trunc %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

rt_pop_mean <- RT_val_m3_trunc %>%
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
rt_pop_post <- RT_val_m3_trunc %>% 
  tidybayes::gather_draws(b_Intercept, b_ValenceBad, b_ValenceGood,
                          `b_ismatch`, `b_ValenceBad:ismatch`, 
                          `b_ValenceGood:ismatch`) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
rt_post_tmp <- merge(rt_pop_post, df_m3_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_m3_rt_plot <- rt_pop_post %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., rt_post_tmp) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
                                                         "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
                                                         "Exp5_THU",  "Exp6a_THU","Overall")),
                condition = forcats::fct_rev(condition)#, # reverse the order b/c plot function auto reverse.
                ) %>%
  tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
  dplyr::mutate(diff_GB_NM = ValenceGood - ValenceBad,               # calculate the differences between coditions
                diff_GN_NM = ValenceGood,
                diff_BN_NM = ValenceBad,
                diff_GN_M = ValenceGood + `ValenceGood:ismatch`,
                diff_BN_M = ValenceBad + `ValenceBad:ismatch`,
                diff_GB_M = diff_GN_M - diff_BN_M) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GB_NM,diff_GN_NM, diff_BN_NM,
               diff_GB_M, diff_GN_M, diff_BN_M) %>%
  tidyr::pivot_longer(cols = diff_GB_NM:diff_BN_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_NM','diff_GN_NM', 'diff_BN_NM',
                                                         'diff_GB_M', 'diff_GN_M', 'diff_BN_M')))

df_m3_rt_plot %>% 
  dplyr::group_by(condition, term_diff, .chain) %>%
  dplyr::tally()

df_m3_rt_mean <- df_m3_rt_plot %>%
  group_by(condition, term_diff) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(value)  # get the high density continuous intervals


# plot the posterior of mismatch
df_m3_rt_plot  %>%
  dplyr::filter(str_detect(term_diff, '_NM')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)

# plot the posterior of matching trials
df_m3_rt_plot %>%
  dplyr::filter(str_detect(term_diff, '_M')) %>%
  ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x < 0))) +
  tidybayes::stat_halfeyeh() +
  geom_vline(xintercept = 0, linetype = "dashed") +
  scale_fill_manual(values = c('gray80', 'skyblue')) + 
  facet_wrap( ~ term_diff,
               scales = "free_y", nrow = 1,
               labeller = label_parsed)
```

# Part 2: interaction between valence and identity

In this part, we report three experiments (3a, 3b, and 6b) that aimed at testing whether the moral valence effect found in the previous experiments is modulated by self-referential processes. These three experiments included  data from 108 participants.

```{r prepare data for second meta, echo=FALSE, results='hide', warning=FALSE}
### try meta-analysis 1a, 1b, 1c, 2, 5 and 6a
selected_columns <- c('ExpID', 'Site', 'Subject','Age', 'Sex', 'Matchness', 'Identity', 'Valence', 'RESP', 'ACC','RT')
df_ms <- dplyr::bind_rows(df3a.v_meta[selected_columns],
                          df3b.v_meta[selected_columns],
                          df6b.v_meta[selected_columns]) %>%
  dplyr::mutate(ExpID_new = paste(ExpID, Site, sep = "_")) %>%
  dplyr::mutate(Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')))

df_ms_subj <- df_ms %>%
  dplyr::group_by(ExpID_new, Site) %>%
  dplyr::summarize(N = n_distinct(Subject),
                   N_trial = length(Subject),
                   Exp_conds = 6,
                   trial_per_cond = round((length(Subject)/6)/N, 0))

df_ms <- df_ms %>%
  dplyr::filter(!is.na(RESP)) %>% # filter trials without response
  dplyr::mutate(ismatch = ifelse(Matchness == 'Match', 1, 0),
                saymatch = ifelse((Matchness == 'Match' & ACC == 1) | 
                                    (Matchness == 'Mismatch' & ACC == 0), 1, 0),
                Valence = factor(Valence, levels = c('Neutral', 'Bad', 'Good')),
                Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
  dplyr::select(ExpID_new, Subject, Matchness, Identity,Valence, RESP, ACC, RT, ismatch, saymatch) %>%
  dplyr::mutate(ismatch_num = ifelse(Matchness == 'Match', 0.5, -0.5))

# plot the nested structure of the data
# with(df_ms, table(Subject, ExpID_new)) %>%
#   image(
#     col = grey.colors(80, start = 1, end = 0), 
#     axes = TRUE, 
#     xlab = "Subject", 
#     ylab = "ExpID"
#   )
```

```{r second meta sdt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for SDT of moral self, didn't specify the prior; dummy coding
# 
# Note: initialization failed for a few times for full model. need to re-consider the model
sdt_ms_m1 <- df_ms %>%
        dplyr::mutate(Subject = as.factor(Subject),
                      ExpID_new = as.factor(ExpID_new)) %>%
        brms::brm(saymatch ~ 0 + Identity:Valence + ismatch:Identity:Valence + 
                          (0 + Identity:Valence + ismatch:Identity:Valence | ExpID_new) + 
                          (0 + Identity:Valence + ismatch:Identity:Valence | ExpID_new:Subject),
                  family = bernoulli(link="probit"),
                  data = .,
                  chains = 6,
                  iter = 4000,
                  thin = 2,
                  control = list(adapt_delta = .90),
                  cores = parallel::detectCores(),
                  backend = 'cmdstanr',  # with cmdstanr
                  file = here::here("glmmModels/sdt_ms_DummyCode_3_level"))

# summary(sdt_ms_m1)

# # Get the variables in the model
var_name_m1 <- tidybayes::get_variables(sdt_ms_m1)

# # get the variable names start with 'b_', i.e., the population level parameters
pop_param_names <- grep('^b_.', var_name_m1, value = TRUE)

# plot the population level parameter (d prime)
sdt_ms_m1_p <- sdt_ms_m1 %>%
  # get the traces of population level parameters
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when(grepl("Neutral", .variable) ~ "Neutral",
                                           grepl("Bad", .variable) ~"Bad",
                                           grepl("Good", .variable) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", .variable) ~ "Self",
                                           grepl("Other", .variable) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "d prime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('d prime', 'criterion')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) %>%
  # select only d prime
  dplyr::filter(params == 'd prime') %>%
  ggplot2::ggplot(aes(x = Valence, y = .value)) +
  tidybayes::stat_halfeye(aes(fill = Identity), alpha = 0.7) + # position=position_dodge(width = 0.1)
  geom_slabinterval(ymin = 0, ymax = 4) +
  stat_summary(aes(group = Identity, color = Identity), fun = mean, geom = "line") +
  ylab(expression(paste("Sensitivity ", italic("d'"), sep = ' '))) +
  # ylim(0, 4) +
  # xlab("Valence") +
  #facet_grid(cols = vars(Identity)) + # , scales = "free_y"
  theme_classic() # + 
  # theme(axis.title.x = element_blank())

#### plot both overall parameters and experimental levels.

df_ms_sdt_m1_post_exp <- sdt_ms_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_ms_sdt_m1_pop_mean <- sdt_ms_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_ms_sdt_m1_pop <- sdt_ms_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_ms_sdt_m1_post_exp_update <- merge(df_ms_sdt_m1_pop, df_ms_sdt_m1_post_exp, by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population level value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_ms_sdt_m1_plot <- df_ms_sdt_m1_pop %>%
  dplyr::mutate(condition = 'Overall') %>%
  dplyr::rename(value = pop_mean) %>%
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
  dplyr::bind_rows(., df_ms_sdt_m1_post_exp_update) %>%
  dplyr::mutate(condition = factor(condition, levels = c("Exp3a_THU", "Exp3b_WZU", "Exp6b_THU",
                                                         "Overall")),
                condition = forcats::fct_rev(condition), # reverse the order because the plot function auto reverse.
                Valence = dplyr::case_when(grepl("Neutral", term) ~ "Neutral",
                                           grepl("Bad", term) ~"Bad",
                                           grepl("Good", term) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", term) ~ "Self",
                                           grepl("Other", term) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", term) ~ "dprime",
                                           !grepl("ismatch", term) ~"c"),
                params = factor(params, levels = c('dprime', 'c')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))
                ) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
p_ms_sdt_vlines <- df_ms_sdt_m1_plot %>% 
        #tidyr::separate(term, c('params', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad'))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::group_by(Identity, Valence) %>% 
        dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_ms_dprime1 <- df_ms_sdt_m1_plot %>%
        # tidyr::separate(term, c('params', 'Valence')) %>%
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(params == 'dprime') %>%
        dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >= 0) & (value <= 4)) %>%  # limit the x-axis's value
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        facet_wrap(~Identity) + 
        geom_vline(data = p_ms_sdt_vlines, aes(xintercept = Mean,colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of '~italic(d)~' prime')) + 
        theme_apa()

# plot the posterior of the difference between d prime
df_ms_sdt_m1_plot_diff <- df_ms_sdt_m1_plot %>%
        tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(
                # diff_GN_c_S = c_Self_Good - c_Self_Neutral,
                # diff_BN_c_S = c_Self_Bad - c_Self_Neutral,
                # diff_GN_c_O = c_Other_Good - c_Other_Neutral,
                # diff_BN_c_O = c_Other_Bad - c_Other_Neutral,
                diff_GN_dprm_S = dprime_Self_Good - dprime_Self_Neutral,
                diff_BN_dprm_S = dprime_Self_Bad - dprime_Self_Neutral,
                diff_GN_dprm_O = dprime_Other_Good - dprime_Other_Neutral,
                diff_BN_dprm_O = dprime_Other_Bad - dprime_Other_Neutral,
                diff_SO_dprm_G = dprime_Self_Good - dprime_Other_Good,
                diff_SO_dprm_N =  dprime_Self_Neutral - dprime_Other_Neutral,
                diff_SO_dprm_B =  dprime_Self_Bad - dprime_Other_Bad
                ) %>%
  dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               diff_GN_dprm_S, diff_BN_dprm_S, diff_GN_dprm_O, diff_BN_dprm_O,
               diff_SO_dprm_G, diff_SO_dprm_N, diff_SO_dprm_B) %>%
  tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_SO_dprm_B, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_dprm_S', 'diff_BN_dprm_S', 'diff_GN_dprm_O', 'diff_BN_dprm_O',
                                                         'diff_SO_dprm_G', 'diff_SO_dprm_N', 'diff_SO_dprm_B')))

p_ms_dprime1_diff_val <- df_ms_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        xlab(expression(paste("Valence effect on ", italic("d"), " prime", sep = ' '))) + 
        facet_wrap( ~ term_diff, # scales = "free_y",
               nrow = 1,
               labeller = label_parsed)

p_ms_dprime1_diff_id <- df_ms_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        xlab(expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' '))) + 
        facet_wrap( ~ term_diff, # scales = "free_y",
               nrow = 1,
               labeller = label_parsed)
# plot the posterior of difference between c, supplementary figure
# df_ms_sdt_m1_plot_diff %>%
#   dplyr::filter(str_detect(term_diff, '_c')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
#   tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
#   dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
#   ggplot2::ggplot(aes(y = condition, x = value, fill = stat(x > 0))) +
#   tidybayes::stat_halfeye() +
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c('gray80', 'skyblue')) +
#   xlab(expression(paste("Valence effect on", italic("d"), "prime", sep = ' ')))+ 
#   expand_limits(x = c(-3, 3)) + 
#   facet_wrap( ~ term_diff, # scales = "free_y",
#                nrow = 1,
#                labeller = label_parsed) 
```

```{r second meta rt, echo=FALSE, results='hide', warning=FALSE}
# fit a three-level hierarchical model for RT, didn't specify the prior, shifted_lognormal, effective coding
RT_ms_m1 <- df_ms %>%
  dplyr::mutate(RT_sec = RT/1000) %>% # log RT in seconds
  dplyr::filter(ACC == 1) %>%         # only correct trials
  brms::brm(RT_sec ~ ismatch*Identity*Valence + 
              (ismatch*Identity*Valence | ExpID_new) +   
              (ismatch*Identity*Valence | ExpID_new:Subject),
            family=shifted_lognormal(),
            data = .,
            chains = 6,
            control = list(adapt_delta = .90),
            # iter = 4000,
            # thin = 2,
            cores = parallel::detectCores(),
            backend = 'cmdstanr',  # with cmdstanr
            file = here::here("glmmModels/RT_ms_DummyCode_3_level"))

# summary(RT_ms_m1)  # ndt = 0 there fore, we used lognormal.
# pp_check(RT_val_m1)

# Population-Level Effects: 
#                                   Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS
# Intercept                            -0.21      0.41    -0.97     0.80 1.02      118      307
# ismatch                              -0.08      0.06    -0.21     0.04 1.06       92      252
# IdentityOther                        -0.04      0.10    -0.29     0.13 1.07       84      134
# ValenceBad                            0.00      0.02    -0.05     0.05 1.05       87       29
# ValenceGood                          -0.04      0.17    -0.55     0.11 1.07       57       37
# ismatch:IdentityOther                -0.09      0.39    -0.95     0.73 1.07       88       28
# ismatch:ValenceBad                    0.01      0.08    -0.17     0.17 1.04      279      274
# ismatch:ValenceGood                  -0.07      0.03    -0.13     0.01 1.06       71       96
# IdentityOther:ValenceBad             -0.00      0.05    -0.09     0.13 1.10       48      140
# IdentityOther:ValenceGood             0.01      0.29    -0.64     0.79 1.14       80       55
# ismatch:IdentityOther:ValenceBad      0.03      0.06    -0.09     0.20 1.05      115       87
# ismatch:IdentityOther:ValenceGood     0.07      0.23    -0.47     0.46 1.03      237      189

# Mismatch:Neutral:Self  - Intercept = -0.21
# Mismatch:Bad:Self      - Intercept  + ValenceBad    = -0.21 + 0.00 = -0.21
# Mismatch:Good:Self     - Intercept  + ValenceGood   = -0.21 - 0.04 = -0.25
# Mismatch:Neutral:Other - Intercept  + IdentityOther = -0.21 - 0.04 = -0.25
# Mismatch:Bad:Other     - Intercept  + ValenceBad  + IdentityOther:ValenceBad  = -0.21 + 0.00 + 0.00 = -0.21
# Mismatch:Good:Other    - Intercept  + ValenceGood + IdentityOther:ValenceGood = -0.21 - 0.04 + 0.01 = -0.24
# Match: Neutral:Self    - Intercept  + ismatch = -0.19 - 0.08 = -0.27
# Match: Bad:Self        - Intercept  + ismatch + ismatch:ValenceBad    = -0.19 - 0.08 + 0.01 = -0.26 
# Match: Good:Self       - Intercept  + ismatch + ismatch:ValenceGood   = -0.19 - 0.08 - 0.07 = -0.34
# Match: Neutral:Other   - Intercept  + ismatch + ismatch:IdentityOther = -0.19 - 0.08 - 0.09 = -0.36
# Match: Bad:Other       - Intercept  + ismatch + ismatch:IdentityOther + ismatch:IdentityOther:ValenceBad  = -0.19 - 0.08 - 0.09 + 0.03 = -0.33 
# Match: Good:Other      - Intercept  + ismatch + ismatch:IdentityOther + ismatch:IdentityOther:ValenceGood = -0.19 - 0.08 - 0.09 + 0.07 = -0.29

# Get the variables in the model 1
# RT_var_name_m1 <- tidybayes::get_variables(RT_val_m1)

df_ms_m1_post_rt_exp <- RT_ms_m1 %>% 
  tidybayes::spread_draws(r_ExpID_new[condition, term]) %>%
  dplyr::rename(value = r_ExpID_new)

df_ms_m1_rt_pop_mean <- RT_ms_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  group_by(.variable) %>%       # this line not necessary (done automatically by spread_draws)
  tidybayes::mean_hdci(.value)  # get the high density continuous intervals

# extract the population level parameters
df_ms_m1_rt_pop <- RT_ms_m1 %>% 
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>%
  dplyr::rename(term = .variable,
                pop_mean = .value) %>%
  #tidyr::separate(term, c(NA, 'term'), "_") 
  dplyr::ungroup() %>%
  dplyr::mutate(term = gsub("b_", "", term))

# Add the population mean to the experimental level and only keep the value after.
df_ms_m1_rt_exp_update <- merge(df_ms_m1_rt_pop, df_ms_m1_post_rt_exp, 
# rt_post_tmp <- merge(rt_pop_post, df_m1_post_rt_exp, 
                     by = c('term','.chain','.iteration', '.draw'), all = T) %>%
  dplyr::mutate(mean_value = pop_mean + value) %>%  # add the population leve value to each experiment
  dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, mean_value) %>% # select the added value
  dplyr::rename(value = mean_value)  # rename the value

# Plot the difference between conditions 
df_ms_m1_plot_rt <- df_ms_m1_rt_pop %>%
        dplyr::mutate(condition = 'Overall') %>%
        dplyr::rename(value = pop_mean) %>% # chagne the `pop_mean` as `value` for data frame merge
        dplyr::select(condition, term, `.chain`, `.iteration`, `.draw`, value) %>%
        dplyr::bind_rows(., df_ms_m1_rt_exp_update) %>%
        dplyr::mutate(condition = factor(condition, levels = c("Exp3a_THU", "Exp3b_WZU", "Exp6b_THU",
                                                               "Overall")),
  # dplyr::mutate(condition = factor(condition, levels = c("Exp1a_THU", "Exp1a_WZU", "Exp1b_THU", 
  #                                                        "Exp1b_WZU", "Exp1c_THU", "Exp2_THU" , 
  #                                                        "Exp5_THU",  "Exp6a_THU","Overall")),
                      condition = forcats::fct_rev(condition)) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(NM_Self_Neutral = Intercept,               # calculate the differences between conditions
                      NM_Self_Bad = Intercept  + ValenceBad,
                      NM_Self_Good = Intercept  + ValenceGood ,
                      NM_Other_Neutral = Intercept  + IdentityOther,               # calculate the differences between conditions
                      NM_Other_Bad = Intercept  + ValenceBad  + `IdentityOther:ValenceBad`,
                      NM_Other_Good = Intercept  + ValenceGood + `IdentityOther:ValenceGood`,
                      M_Self_Neutral = Intercept  + ismatch,
                      M_Self_Bad = Intercept  + ismatch + `ismatch:ValenceBad`,
                      M_Self_Good = Intercept  + ismatch + `ismatch:ValenceGood`,
                      M_Other_Neutral = Intercept  + ismatch + `ismatch:IdentityOther`,
                      M_Other_Bad = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceBad`,
                      M_Other_Good = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceGood`) %>%
        dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
               contains('M_')) %>%
  tidyr::pivot_longer(cols = NM_Self_Neutral:M_Other_Good, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('NM_Self_Neutral', 'NM_Self_Bad', 'NM_Self_Good',
                                               'NM_Other_Neutral', 'NM_Other_Bad', 'NM_Other_Good',
                                               'M_Self_Neutral', 'M_Self_Bad', 'M_Self_Good',
                                               'M_Other_Neutral', 'M_Other_Bad', 'M_Other_Good')),
                value = exp(value),
                value = value * 1000) 

# plot the posterior of the d prime
# use the overall mean values as the vlines
p_ms_rt1_vlines <- df_ms_m1_plot_rt %>% 
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::filter(condition == "Overall") %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        dplyr::group_by(Identity, Valence) %>% 
        tidybayes::median_hdci(value)
        #dplyr::summarize(Mean = mean(value)) # %>%
        # dplyr::arrange(Mean)

# THIS is the one which the final plot will based on!!!
p_ms_rt1 <- df_ms_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        geom_vline(data = p_ms_rt1_vlines, aes(xintercept = value, colour = Valence), linetype = "dashed") +
        labs(x=expression('Posteior distribution of RTs')) + 
        facet_wrap(~Identity) + 
        theme_apa()

df_ms_m1_plot_rt_diff <- df_ms_m1_plot_rt %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        # calculate the difference between conditions, matched trials only
        dplyr::mutate(diff_GN_M_S = M_Self_Good - M_Self_Neutral,               # calculate the differences between conditions
                      diff_BN_M_S = M_Self_Bad - M_Self_Neutral,
                      diff_GN_M_O = M_Other_Good - M_Other_Neutral,  
                      diff_BN_M_O = M_Other_Bad - M_Other_Neutral,
                      diff_SO_G   = M_Self_Good - M_Other_Good, 
                      diff_SO_N   = M_Self_Neutral - M_Other_Neutral,
                      diff_SO_B   = M_Self_Bad - M_Other_Bad) %>%
        dplyr::select(condition, `.chain`, `.iteration`, `.draw`,
                      diff_GN_M_S, diff_BN_M_S, diff_GN_M_O,
                      diff_BN_M_O, diff_SO_G, diff_SO_N, diff_SO_B) %>%
        tidyr::pivot_longer(cols = diff_GN_M_S:diff_SO_B, names_to = "term_diff", values_to =  "value")  %>%  # wide to long
        dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_M_S','diff_BN_M_S', 'diff_GN_M_O', 'diff_BN_M_O',
                                                                'diff_SO_G', 'diff_SO_N', 'diff_SO_B')))

# plot the posterior of matching trials of valence
p_ms_rt1_diff_val <- df_ms_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_M_')) %>%
        dplyr::filter((value >= -200) & (value <= 200)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) + 
        xlab("Valence effect on RTs (Match trials)") +
        facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)

# plot the posterior of matching trials, diff between self and other
p_ms_rt1_diff_id <- df_ms_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::filter((value >= -200) & (value <= 200)) %>%
        dplyr::rename(Experiments = condition) %>%
        ggplot2::ggplot(aes(y = Experiments, x = value, fill = stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) + 
        xlab("Self-referential effect on RTs (Match trials)") +
        facet_wrap( ~ term_diff,
              # scales = "free_y", 
              nrow = 1,
              labeller = label_parsed)
```


```{r plot-bayes2, fig.cap="Interaction between moral valence and self-referential", fig.height=12, fig.width=15, warning=FALSE}
library(patchwork)
# (p_rt1 | p_dprime1)
p_ms_rt1 + p_ms_dprime1 +
        p_ms_rt1_diff_val + p_ms_dprime1_diff_val + 
        p_ms_rt1_diff_id + p_ms_dprime1_diff_id +  plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 3, byrow = TRUE, guides = "collect")
```

See Figure \@ref(fig:plot-bayes2).

# Part 3: Implicit binding between valence and identity

In this part, we reported two studies in which the moral valence or the self-referential processing is not task-relevant. We are interested in testing whether the task-relevance will eliminate the effect observed in previous experiment. 

```{r 4a_BGLMM_sdt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4a'
exp4a_sdt_m1 <- fun_sdt_val_id(exp_name)

#summary(exp4a_sdt_m1)    # check summary

# check fixed and varying effect using bayestestR
# bayestestR::describe_posterior(
#   exp4a_sdt_m1,
#   effects = "all",
#   component = "all",
#   test = c("p_direction", "p_significance"),
#   centrality = "all"
# )
#pp_check(exp4a_sdt_m1)   # posterior predictive check

# d-prime
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceNeutral:ismatch")      # .82
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceBad:ismatch")          # .75
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentitySelf:ValenceBad:ismatch")       # .44
hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceNeutral:ismatch")    # .11
hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceBad:ismatch")        # .07
hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceNeutral:ismatch > IdentityOther:ValenceBad:ismatch")     # .39

hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentityOther:ValenceGood:ismatch")        # 1
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentityOther:ValenceNeutral:ismatch")  # 1
hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceBad:ismatch > IdentityOther:ValenceBad:ismatch")          # 1

# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood > IdentitySelf:ValenceNeutral")  # .73
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood > IdentitySelf:ValenceBad")  # .9
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral > IdentitySelf:ValenceBad")  # .49
# hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood > IdentityOther:ValenceNeutral")  # .68
# hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceGood > IdentityOther:ValenceBad")  # .92
# hypothesis(exp4a_sdt_m1, "IdentityOther:ValenceNeutral> IdentityOther:ValenceBad")  # .8
# 
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceGood > IdentityOther:ValenceGood")  # .92
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceNeutral > IdentityOther:ValenceNeutral")  # .76
# hypothesis(exp4a_sdt_m1, "IdentitySelf:ValenceBad > IdentityOther:ValenceBad")  # .96

# extract the population level parameters
# criteria

df_exp4a_sdt_m1_plot <- exp4a_sdt_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>% # get the traces of population level parameters
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when(grepl("Neutral", .variable) ~ "Neutral",
                                           grepl("Bad", .variable) ~"Bad",
                                           grepl("Good", .variable) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", .variable) ~ "Self",
                                           grepl("Other", .variable) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "dprime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('dprime', 'criterion')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) 

exp4a_sdt_p <- df_exp4a_sdt_m1_plot %>%
  dplyr::filter(params == 'dprime') %>%  # select only d prime
  ggplot2::ggplot(aes(x = Identity, y = .value, color = Valence)) +
  tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) + # position=position_dodge(width = 0.1)
  # geom_slabinterval(ymin = 0, ymax = 4) +
  stat_summary(aes(group = Valence, color = Valence), fun = mean, geom = "line") +
  labs(x = expression("Self-Referential"), 
      y = expression(paste("Posteior of sensitivity ", italic("d'"), sep = ' '))) +
  scale_colour_brewer(palette = "Dark2") +
  scale_fill_brewer(palette = "Dark2") +
  # facet_grid(~ params , scales = "free_y") +
  theme_classic() 

# exp4a_sdt_p <- exp4a_sdt_m1 %>%
#   emmeans::emmeans( ~ ismatch | Identity| Valence) %>%
#   tidybayes::gather_emmeans_draws() %>%
#   dplyr::mutate(ismatch = ifelse(ismatch == 0, 'criterion', 'd prime'),
#                 ismatch = factor(ismatch, levels = c('d prime', 'criterion')),
#                 Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad')),
#                 Identity = factor(Identity, levels = c('Self', 'Other'))) %>%
#   ggplot2::ggplot(aes(x = Valence, y = .value, group = Identity, color = Identity)) +
#   #ggplot2::ggplot(aes(x = Valence, y = .value, group = .draw)) +
#   #geom_line(alpha = .01) +
#   scale_colour_brewer(palette = "Dark2") +
#   scale_fill_brewer(palette = "Dark2") +
#   tidybayes::stat_halfeye() + # position=position_dodge(width = 0.1)
#   stat_summary(aes(group = Identity, color = Identity), fun.y = mean, geom = "line"
#                #,position=position_dodge(width = 0.1)
#                ) +
#   #scale_fill_brewer() +
#   facet_grid(~ ismatch) +
#   theme_classic()

df_exp4a_sdt_m1_plot_diff <- df_exp4a_sdt_m1_plot %>%
        tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `.value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = .value) %>%   # long to wide
        dplyr::mutate(
                # diff_GN_c_S = c_Self_Good - c_Self_Neutral,
                # diff_BN_c_S = c_Self_Bad - c_Self_Neutral,
                # diff_GN_c_O = c_Other_Good - c_Other_Neutral,
                # diff_BN_c_O = c_Other_Bad - c_Other_Neutral,
                diff_GN_dprm_S = dprime_Self_Good - dprime_Self_Neutral,
                diff_BN_dprm_S = dprime_Self_Bad - dprime_Self_Neutral,
                diff_GB_dprm_S = dprime_Self_Good - dprime_Self_Bad,
                diff_GN_dprm_O = dprime_Other_Good - dprime_Other_Neutral,
                diff_BN_dprm_O = dprime_Other_Bad - dprime_Other_Neutral,
                diff_GB_dprm_O = dprime_Other_Good - dprime_Other_Bad,
                diff_SO_dprm_G = dprime_Self_Good - dprime_Other_Good,
                diff_SO_dprm_N =  dprime_Self_Neutral - dprime_Other_Neutral,
                diff_SO_dprm_B =  dprime_Self_Bad - dprime_Other_Bad,
                diff_diff_GN_SO = diff_GN_dprm_S - diff_GN_dprm_O,
                diff_diff_GB_SO = diff_GB_dprm_S - diff_GB_dprm_O,
                diff_diff_BN_SO = diff_BN_dprm_S - diff_BN_dprm_O
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_dprm_S:diff_diff_BN_SO) %>%
  tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_diff_BN_SO, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_dprm_S', 'diff_GN_dprm_S', 'diff_BN_dprm_S', 
                                                         'diff_GB_dprm_O', 'diff_GN_dprm_O', 'diff_BN_dprm_O', 
                                                         'diff_SO_dprm_G', 'diff_SO_dprm_N', 'diff_SO_dprm_B',
                                                         'diff_diff_GN_SO', 'diff_diff_GB_SO', 'diff_diff_BN_SO')))
p_exp4a_dprime1_diff_val <- df_exp4a_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                           grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        # dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression(paste("Valence effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

p_exp4a_dprime1_diff_id <- df_exp4a_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts (Self vs. Other)"))

p_exp4a_dprime1_diff_diff <- df_exp4a_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_diff_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "GB",
                                                   grepl("_GN", term_diff) ~"GN",
                                                   grepl("_BN", term_diff) ~ "BN"),
                      term_diff = factor(term_diff, levels = c("GN", "GB", "BN"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Difference (Self vs. Other) of difference (Valence)"))
```

```{r 4a_BGLMM_rt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4a'
exp4a_rt_m1 <- fun_rt_val_id(exp_name)

# summary(exp4a_rt_m1)  # n
# 
# bayestestR::describe_posterior(
#   exp4a_rt_m1,
#   effects = "fixed",
#   component = "all",
#   test = c("p_direction", "p_significance"),
#   centrality = "all"
# )

#pp_check(exp4a_rt_m1)
# rg <- emmeans::ref_grid(exp4a_rt_m1)
# em <- emmeans::emmeans(rg, 'ismatch')
# summary(em, point.est = median)
# emmeans::joint_tests(exp4a_rt_m1)

df_exp4a_m1_plot_rt <- exp4a_rt_m1 %>%
        tidybayes::gather_draws(`b_.*`, regex = TRUE)  %>%
        dplyr::mutate(.variable = gsub("b_", "", .variable)) %>%
        tidyr::pivot_wider(names_from = c(.variable), values_from = .value) %>%
        dplyr::mutate(NM_Self_Neutral = Intercept,               # calculate the differences between conditions
                      NM_Self_Bad = Intercept  + ValenceBad,
                      NM_Self_Good = Intercept  + ValenceGood ,
                      NM_Other_Neutral = Intercept  + IdentityOther,               # calculate the differences between conditions
                      NM_Other_Bad = Intercept  + ValenceBad  + `ValenceBad:IdentityOther`,
                      NM_Other_Good = Intercept  + ValenceGood + `ValenceGood:IdentityOther`,
                      M_Self_Neutral = Intercept  + ismatch,
                      M_Self_Bad = Intercept  + ismatch + `ismatch:ValenceBad`,
                      M_Self_Good = Intercept  + ismatch + `ismatch:ValenceGood`,
                      M_Other_Neutral = Intercept  + ismatch + `ismatch:IdentityOther`,
                      M_Other_Bad = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:ValenceBad:IdentityOther`,
                      M_Other_Good = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:ValenceGood:IdentityOther`) %>%
        dplyr::select(`.chain`, `.iteration`, `.draw`, contains('M_')) %>%
        tidyr::pivot_longer(cols = NM_Self_Neutral:M_Other_Good, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('NM_Self_Neutral', 'NM_Self_Bad', 'NM_Self_Good',
                                               'NM_Other_Neutral', 'NM_Other_Bad', 'NM_Other_Good',
                                               'M_Self_Neutral', 'M_Self_Bad', 'M_Self_Good',
                                               'M_Other_Neutral', 'M_Other_Bad', 'M_Other_Good')),
                value = exp(value),
                value = value * 1000) 

p_exp4a_rt1 <- df_exp4a_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        # dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        ggplot2::ggplot(aes(y = value, x = Identity, color = Valence)) +
        tidybayes::stat_halfeye(aes(fill = Valence), alpha = 0.7) +
        stat_summary(aes(group = Valence, color = Valence), fun = mean, geom = "line") +
        # geom_vline(data = p_ms_rt1_vlines, aes(xintercept = value, colour = Valence), linetype = "dashed") +
        labs(x = expression("Self-Referential"), 
             y = expression('Posteior of reaction times')) +
        scale_colour_brewer(palette = "Dark2") +
        scale_fill_brewer(palette = "Dark2") +
        # facet_grid(~ params , scales = "free_y") +
        theme_classic()
        # facet_wrap(~Identity) + 
        #theme_apa()
# 
# emm1 <- emmeans::emmeans(exp4a_rt_m1, specs = pairwise ~ Identity | Valence | ismatch)
# emm1$contrasts %>% summary(infer = TRUE, point.est = mean)
# 
# emm2 <- emmeans::emmeans(exp4a_rt_m1, specs = pairwise ~ Valence | Identity | ismatch)
# emm2$contrasts %>% summary(infer = TRUE, point.est = mean)

df_exp4a_m1_plot_rt_diff <- df_exp4a_m1_plot_rt %>%
        # tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(
                diff_GN_S_RT_M = M_Self_Good - M_Self_Neutral,
                diff_BN_S_RT_M = M_Self_Bad - M_Self_Neutral,
                diff_GB_S_RT_M = M_Self_Good - M_Self_Bad,
                diff_GN_O_RT_M = M_Other_Good - M_Other_Neutral,
                diff_BN_O_RT_M = M_Other_Bad - M_Other_Neutral,
                diff_GB_O_RT_M = M_Other_Good - M_Other_Bad,
                diff_SO_G_RT_M = M_Self_Good - M_Other_Good,
                diff_SO_N_RT_M = M_Self_Neutral - M_Other_Neutral,
                diff_SO_B_RT_M = M_Self_Bad - M_Other_Bad,
                diff_diff_GN_SO = diff_GN_S_RT_M - diff_GN_O_RT_M,
                diff_diff_GB_SO = diff_GB_S_RT_M - diff_GB_O_RT_M,
                diff_diff_BN_SO = diff_BN_S_RT_M - diff_BN_O_RT_M
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_S_RT_M:diff_diff_BN_SO) %>%
  tidyr::pivot_longer(cols = diff_GN_S_RT_M:diff_diff_BN_SO, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_S_RT_M', 'diff_BN_S_RT_M', 'diff_GB_S_RT_M', 
                                                         'diff_GN_O_RT_M', 'diff_BN_O_RT_M', 'diff_GB_O_RT_M', 
                                                         'diff_SO_G_RT_M', 'diff_SO_N_RT_M', 'diff_SO_B_RT_M',
                                                         'diff_diff_GN_SO', 'diff_diff_GB_SO', 'diff_diff_BN_SO')))
p_exp4a_rt_diff_val <- df_exp4a_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_S_RT_M|_O_RT_M')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                                  grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        # dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression("Valence effect on RTs "),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

p_exp4a_rt_diff_id <- df_exp4a_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        # dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression("Self-referential effect on RTs "),
             y = expression("Contrasts (Self vs. Other)"))

p_exp4a_rt1_diff_diff <- df_exp4a_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_diff_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "GB",
                                                   grepl("_GN", term_diff) ~"GN",
                                                   grepl("_BN", term_diff) ~ "BN"),
                      term_diff = factor(term_diff, levels = c("GN", "GB", "BN"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression("Interaction effect on RT"),
             y = expression("Difference (Self vs. Other) of difference (Valence)"))
```

```{r plot-exp4a-BGLM, fig.cap="exp4a: Results of Bayesian GLM analysis.",  fig.height=9, fig.width=12, warning=FALSE}
library(patchwork)
p1 <- (p_exp4a_rt1 + exp4a_sdt_p) #+ plot_layout(nrow = 1, guides = "collect") 
p2 <- (p_exp4a_rt_diff_val + p_exp4a_dprime1_diff_val) + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
# p3 <- p_exp4a_rt_diff_id + p_exp4a_dprime1_diff_id + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
#p1/ 
#        p2  +  plot_layout(nrow = 2)  
        # p3 +  plot_layout(nrow = 3) 
```

For the task relevant part, we found self-related conditions were performed better than other-related conditions, on both *d* prime and reaction times.

Most importantly, we found evidence, albeit weak, that task-irrelevant moral valence also played an role. The *d* prime is greater when shapes were associated with good self condition than with neutral self (BF = 4.4) or bad self (3.1), but shapes associated with bad self and neutral self didn't show differences. In contrast the *d* prime was smaller when shapes were associated with good other than with neutral other or bad other. See Figure \@ref(fig:plot-exp4-all).

```{r 4b_BGLMM_sdt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4b'
exp4b_sdt_m1 <- fun_sdt_val_id(exp_name)

# d-prime
# hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceNeutral:ismatch")     # .98
# hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentitySelf:ValenceBad:ismatch")         # 1
# hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentitySelf:ValenceBad:ismatch")      # .86
# hypothesis(exp4b_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceNeutral:ismatch")   # .91
# hypothesis(exp4b_sdt_m1, "IdentityOther:ValenceGood:ismatch > IdentityOther:ValenceBad:ismatch")       # .91
# hypothesis(exp4b_sdt_m1, "IdentityOther:ValenceNeutral:ismatch > IdentityOther:ValenceBad:ismatch")    # .65

hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceGood:ismatch > IdentityOther:ValenceGood:ismatch")        # .92
hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceNeutral:ismatch > IdentityOther:ValenceNeutral:ismatch")  # .67
hypothesis(exp4b_sdt_m1, "IdentitySelf:ValenceBad:ismatch > IdentityOther:ValenceBad:ismatch")          # .29

# extract the population level parameters
# criteria

df_exp4b_sdt_m1_plot <- exp4b_sdt_m1 %>%
  tidybayes::gather_draws(`b_.*`, regex = TRUE) %>% # get the traces of population level parameters
  # create two columns for two independent factors.
  dplyr::mutate(Valence = dplyr::case_when(grepl("Neutral", .variable) ~ "Neutral",
                                           grepl("Bad", .variable) ~"Bad",
                                           grepl("Good", .variable) ~"Good"),
                Identity = dplyr::case_when(grepl("Self", .variable) ~ "Self",
                                           grepl("Other", .variable) ~"Other"),
                params = dplyr::case_when(grepl("ismatch", .variable) ~ "dprime",
                                           !grepl("ismatch", .variable) ~"criterion"),
                params = factor(params, levels = c('dprime', 'criterion')),
                Identity = factor(Identity, levels = c("Self", "Other")),
                Valence = factor(Valence, levels = c('Good', 'Neutral',  'Bad'))) 

exp4b_sdt_p <- df_exp4b_sdt_m1_plot %>%
  dplyr::filter(params == 'dprime') %>%  # select only d prime
  ggplot2::ggplot(aes(x = Valence, y = .value, color = Identity)) +
  tidybayes::stat_halfeye(aes(fill = Identity), alpha = 0.7) + # position=position_dodge(width = 0.1)
  stat_summary(aes(group = Identity, color = Identity), fun = mean, geom = "line") +
  labs(x = expression("Valence"), 
      y = expression(paste("Posteior of sensitivity ", italic("d'"), sep = ' '))) +
  #scale_colour_brewer(palette = "Dark2") +
  #scale_fill_brewer(palette = "Dark2") +
  theme_classic() 

df_exp4b_sdt_m1_plot_diff <- df_exp4b_sdt_m1_plot %>%
        tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `.value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = .value) %>%   # long to wide
        dplyr::mutate(
                diff_GN_dprm_S = dprime_Self_Good - dprime_Self_Neutral,
                diff_BN_dprm_S = dprime_Self_Bad - dprime_Self_Neutral,
                diff_GB_dprm_S = dprime_Self_Good - dprime_Self_Bad,
                diff_GN_dprm_O = dprime_Other_Good - dprime_Other_Neutral,
                diff_BN_dprm_O = dprime_Other_Bad - dprime_Other_Neutral,
                diff_GB_dprm_O = dprime_Other_Good - dprime_Other_Bad,
                diff_SO_dprm_G = dprime_Self_Good - dprime_Other_Good,
                diff_SO_dprm_N =  dprime_Self_Neutral - dprime_Other_Neutral,
                diff_SO_dprm_B =  dprime_Self_Bad - dprime_Other_Bad
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_dprm_S, diff_BN_dprm_S, diff_GB_dprm_S,
               diff_GN_dprm_O, diff_BN_dprm_O, diff_GB_dprm_O, 
               diff_SO_dprm_G, diff_SO_dprm_N, diff_SO_dprm_B) %>%
  tidyr::pivot_longer(cols = diff_GN_dprm_S:diff_SO_dprm_B, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GB_dprm_S', 'diff_GN_dprm_S', 'diff_BN_dprm_S', 
                                                         'diff_GB_dprm_O', 'diff_GN_dprm_O', 'diff_BN_dprm_O', 
                                                         'diff_SO_dprm_G', 'diff_SO_dprm_N', 'diff_SO_dprm_B')))
p_exp4b_dprime1_diff_val <- df_exp4b_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_dprm_S|_dprm_O')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                           grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        #dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression(paste("Valence effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

p_exp4b_dprime1_diff_id <- df_exp4b_sdt_m1_plot_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        #dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x > 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) +
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression(paste("Self-referential effect on ", italic("d"), " prime", sep = ' ')),
             y = expression("Contrasts (Self vs. Other)"))
```

```{r 4b_BGLMM_rt, echo=FALSE, results='hide', warning=FALSE, message=FALSE}
exp_name <- '4b'
exp4b_rt_m1 <- fun_rt_val_id(exp_name)

df_exp4b_m1_plot_rt <- exp4b_rt_m1 %>%
        tidybayes::gather_draws(`b_.*`, regex = TRUE)  %>%
        dplyr::mutate(.variable = gsub("b_", "", .variable)) %>%
        tidyr::pivot_wider(names_from = c(.variable), values_from = .value) %>%
        dplyr::mutate(NM_Self_Neutral = Intercept,               # calculate the differences between conditions
                      NM_Self_Bad = Intercept  + ValenceBad,
                      NM_Self_Good = Intercept  + ValenceGood ,
                      NM_Other_Neutral = Intercept  + IdentityOther,               # calculate the differences between conditions
                      NM_Other_Bad = Intercept  + ValenceBad  + `IdentityOther:ValenceBad`,
                      NM_Other_Good = Intercept  + ValenceGood + `IdentityOther:ValenceGood`,
                      M_Self_Neutral = Intercept  + ismatch,
                      M_Self_Bad = Intercept  + ismatch + `ismatch:ValenceBad`,
                      M_Self_Good = Intercept  + ismatch + `ismatch:ValenceGood`,
                      M_Other_Neutral = Intercept  + ismatch + `ismatch:IdentityOther`,
                      M_Other_Bad = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceBad`,
                      M_Other_Good = Intercept  + ismatch + `ismatch:IdentityOther` + `ismatch:IdentityOther:ValenceGood`) %>%
        dplyr::select(`.chain`, `.iteration`, `.draw`, contains('M_')) %>%
        tidyr::pivot_longer(cols = NM_Self_Neutral:M_Other_Good, names_to = "term", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term = factor(term, levels = c('NM_Self_Neutral', 'NM_Self_Bad', 'NM_Self_Good',
                                               'NM_Other_Neutral', 'NM_Other_Bad', 'NM_Other_Good',
                                               'M_Self_Neutral', 'M_Self_Bad', 'M_Self_Good',
                                               'M_Other_Neutral', 'M_Other_Bad', 'M_Other_Good')),
                value = exp(value),
                value = value * 1000) 

p_exp4b_rt1 <- df_exp4b_m1_plot_rt %>%
        tidyr::separate(term, c('Match', 'Identity', 'Valence')) %>% 
        dplyr::mutate(Valence = factor(Valence, levels = c('Good', 'Neutral', 'Bad')),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::filter(Match == 'M') %>%
        # dplyr::rename(Experiments = condition) %>%
        dplyr::filter((value >=200) & (value <=1200)) %>%
        ggplot2::ggplot(aes(y = value, x = Valence, color = Identity)) +
        tidybayes::stat_halfeye(aes(fill = Identity), alpha = 0.7) +
        stat_summary(aes(group = Identity, color = Identity), fun = mean, geom = "line") +
        # geom_vline(data = p_ms_rt1_vlines, aes(xintercept = value, colour = Valence), linetype = "dashed") +
        labs(x = expression("Valence"), 
             y = expression('Posteior of reaction times')) +
        #scale_colour_brewer(palette = "Dark2") +
        #scale_fill_brewer(palette = "Dark2") +
        theme_classic()

df_exp4b_m1_plot_rt_diff <- df_exp4b_m1_plot_rt %>%
        # tidyr::unite(term, c('params', 'Identity', 'Valence')) %>%
        dplyr::ungroup() %>%
        dplyr::select(term, `.chain`, `.iteration`, `.draw`, `value`) %>%
        tidyr::pivot_wider(names_from = c(term), values_from = value) %>%   # long to wide
        dplyr::mutate(
                diff_GN_S_RT_M = M_Self_Good - M_Self_Neutral,
                diff_BN_S_RT_M = M_Self_Bad - M_Self_Neutral,
                diff_GB_S_RT_M = M_Self_Good - M_Self_Bad,
                diff_GN_O_RT_M = M_Other_Good - M_Other_Neutral,
                diff_BN_O_RT_M = M_Other_Bad - M_Other_Neutral,
                diff_GB_O_RT_M = M_Other_Good - M_Other_Bad,
                diff_SO_G_RT_M = M_Self_Good - M_Other_Good,
                diff_SO_N_RT_M = M_Self_Neutral - M_Other_Neutral,
                diff_SO_B_RT_M = M_Self_Bad - M_Other_Bad
                ) %>%
  dplyr::select(`.chain`, `.iteration`, `.draw`,
               diff_GN_S_RT_M:diff_SO_B_RT_M) %>%
  tidyr::pivot_longer(cols = diff_GN_S_RT_M:diff_SO_B_RT_M, names_to = "term_diff", values_to =  "value") %>%  # wide to long
  dplyr::mutate(term_diff = factor(term_diff, levels = c('diff_GN_S_RT_M', 'diff_BN_S_RT_M', 'diff_GB_S_RT_M', 
                                                         'diff_GN_O_RT_M', 'diff_BN_O_RT_M', 'diff_GB_O_RT_M', 
                                                         'diff_SO_G_RT_M', 'diff_SO_N_RT_M', 'diff_SO_B_RT_M')))
df_exp4b_m1_plot_rt_diff %>% 
        dplyr::filter(term_diff == 'diff_SO_G_RT_M') %>%  dplyr::pull(value) %>%
        bayestestR::describe_posterior(., centrality = "mean",
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"))

df_exp4b_m1_plot_rt_diff %>% 
        dplyr::filter(term_diff == 'diff_SO_N_RT_M') %>%  dplyr::pull(value) %>%
        bayestestR::describe_posterior(., centrality = "mean",
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"))

df_exp4b_m1_plot_rt_diff %>% 
        dplyr::filter(term_diff == 'diff_SO_B_RT_M') %>%  dplyr::pull(value) %>%
        bayestestR::describe_posterior(., centrality = "mean",
                                       ci = 0.95,
                                       ci_method = 'hdi',
                                       test = c("p_direction", "p_significance"))

p_exp4b_rt_diff_val <- df_exp4b_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_S_RT_M|_O_RT_M')) %>%
        dplyr::mutate(Identity = dplyr::case_when(grepl("_S", term_diff) ~ "Self",
                                                  grepl("_O", term_diff) ~"Other"),
                      Identity = factor(Identity, levels = c("Self", "Other"))) %>%
        dplyr::mutate(term_diff = stringr::str_sub(.$term_diff, end = -8)) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_GB", term_diff) ~ "Good vs. Bad",
                                                   grepl("_GN", term_diff) ~"Good vs. Neutral",
                                                   grepl("_BN", term_diff) ~ "Bad vs. Neutral"),
                      term_diff = factor(term_diff, levels = c("Good vs. Bad", "Good vs. Neutral", "Bad vs. Neutral"))) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('gray80', 'skyblue')) +
        labs(x = expression("Valence effect on RTs "),
             y = expression("Contrasts")) + 
        facet_wrap( ~ Identity, nrow = 1)

p_exp4b_rt_diff_id <- df_exp4b_m1_plot_rt_diff %>%
        dplyr::filter(str_detect(term_diff, '_SO_')) %>%
        dplyr::mutate(term_diff = dplyr::case_when(grepl("_B", term_diff) ~ "Bad",
                                                   grepl("_N", term_diff) ~"Neutral",
                                                   grepl("_G", term_diff) ~ "Good"),
                      term_diff = factor(term_diff, levels = c("Good", "Neutral", "Bad"))) %>%
        # dplyr::filter(!str_detect(term_diff, '_GB_')) %>%
        # tidyr::unite(term_diff, c('Identity', 'term_diff')) %>%
        # dplyr::filter((value >= -1.5) & (value <= 1.5)) %>%
        dplyr::rename(conditions = term_diff) %>%
        ggplot2::ggplot(aes(x = value, y = fct_rev(conditions), fill = stat(x < 0))) +
        tidybayes::stat_halfeye() +
        geom_vline(xintercept = 0, linetype = "dashed") +
        scale_fill_manual(values = c('skyblue', 'gray80'),
                    breaks = c(TRUE, FALSE),
                    name = "Effect" , labels = c("Yes", "No")) + 
        # scale_fill_manual(values = c('skyblue')) +   # note: only one value here, used blue here
        labs(x = expression("Self-referential effect on RTs "),
             y = expression("Contrasts (Self vs. Other)"))

```

```{r plot-exp4b-BGLM, fig.cap="exp4a: Results of Bayesian GLM analysis.",  fig.height=9, fig.width=12, warning=FALSE}
library(patchwork)
p3 <- (p_exp4b_rt1 + exp4b_sdt_p ) + plot_layout(nrow = 1, guides = "collect") 
# p2 <- p_exp4b_rt_diff_val + p_exp4b_dprime1_diff_val + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
p4 <- (p_exp4b_rt_diff_id + p_exp4b_dprime1_diff_id) + plot_layout(nrow = 1, byrow = FALSE, guides = "collect") 
```

```{r plot-exp4-all, fig.cap="exp4: Results of Bayesian GLM analysis.",  fig.height=9, fig.width=15, warning=FALSE}
library(patchwork)

design <- "
  1234
  5678
"
p_exp4a_rt1 + exp4a_sdt_p + p_exp4b_rt1 + exp4b_sdt_p + p_exp4a_rt_diff_val + p_exp4a_dprime1_diff_val + p_exp4b_rt_diff_id + p_exp4b_dprime1_diff_id  + plot_layout(design = design, guides = "collect")

# ((p1 +plot_layout(guides = "collect")) + p3 + plot_layout(guides = "collect")) + plot_layout(ncol = 3, widths = c(1, 1, 4), guides = 'keep')
# 
# (((p_exp4a_rt1 + exp4a_sdt_p + plot_layout(guides = "collect", nrow = 1)) + 
#                 (p_exp4b_rt1 + exp4b_sdt_p + plot_layout(guides = "collect", nrow = 1)) + plot_layout(nrow = 1)) + 
#         ((p_exp4a_rt_diff_val + p_exp4a_dprime1_diff_val + plot_layout(guides = "collect", nrow = 1)) 
#          + (p_exp4b_rt_diff_id + p_exp4b_dprime1_diff_id + plot_layout(guides = "collect", nrow = 1)) + plot_layout(nrow = 1))) + 
#         plot_layout(design = design, guides = "keep") +  plot_annotation(tag_levels = 'A')  

```


In this task, we found shapes associated with good person conditions were performed better than other-related conditions, on both *d* prime and reaction times.

Most importantly, we found evidence, that task-irrelevant self-relevance also played an role. For shapes associated with good person, the *d* prime was greater when shapes had an "self" inside as task-irrelevant stimuli than with "other" inside (mean_diff = 0.14, 95% credible intervals [-0.02, 0.31], BF = 12.07, p = 0.92), but this effect did not happen when the target shape where associated with "neutral" (mean_diff = 0.04, 95% CI [-.11, .18]) or "bad" person (mean_diff = -.05, 95% CI[-.18, .09]). The same trend appear for the RT data. For shapes associated with good person, an "self" inside will reduce the RTs as compared with when a "other" inside the shape (mean_diff = -55 ms, 95%CI[-75, -35], p < 0.0001), but this effect did not occur when the shapes were associated neutral (mean_dfiff = 10, 95% CI [1, 20]) or bad (mean_diff = 5, 95%CI [-16, 27]) person. See Figure \@ref(fig:plot-exp4-all).

## Self-reported personal distance

```{r personal distance, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
# prepare questionnaire data
df.scales <- read.csv(here::here("Scale_data", "FADGS_dataset4ID_clean.csv"), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
  dplyr::mutate(expID = dplyr::case_when(
                                    (expID == "exp1.0") ~ "Exp1a",
                                    (expID == "exp1.1") ~ "Exp1b",
                                    (expID == "exp3")   ~ "Exp3a",
                                    (expID == "exp3.1") ~ "Exp3b",
                                    (expID == "exp4.1") ~ "Exp4a",
                                    (expID == "exp4.2") ~ "Exp4b",
                                    (expID == "exp5.2") ~ "Exp5",
                                    (expID == "exp6.2") ~ "Exp6b",
                                    (expID == "exp7.1") ~ "Exp7a",
                                    (expID == "exp7r")  ~ "Exp7b",
                                    (expID == "exp6")   ~ "Exp_dpr"))

## get the questionnaire names
# Self-esteem
SlfEstNames <- c("SES1","SES2","SES3","SES4","SES5","SES6","SES7","SES8","SES9","SES10")
SlfEstNames_r <- c("SES1","SES2","SES3_r","SES4","SES5_r","SES6","SES7","SES8","SES9_r","SES10_r")

# moral identity
mrlIdNames <- c("morId_1","morId_2","morId_3","morId_4", "morId_5","morId_6",
                "morId_7","morId_8","morId_9","morId_10","morId_11","morId_12",
                "morId_13","morId_14","morId_15","morId_16")

mrlIdIntNames <- c("morId_1","morId_2","morId_5","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdIntNames_r <- c("morId_1","morId_2","morId_5_r","morId_8", "morId_10","morId_11",
                   "morId_12","morId_13","morId_14")
mrlIdExtNames <- c("morId_3","morId_4", "morId_6", "morId_7", "morId_9",
                   "morId_15", "morId_16")

# moral self images
mrlslfImgNames <- c("morSlfImg_1","morSlfImg_2","morSlfImg_3","morSlfImg_4",
                    "morSlfImg_5","morSlfImg_6","morSlfImg_7","morSlfImg_8","morSlfImg_9")

# personal distance
perDistNames <- c("SelfSelf", 
                  "SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "SelfStra_1", "SelfStra_2", "SelfStra_3", "SelfStra_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

perDistNames2 <- c("SelfGood_1", "SelfGood_2", "SelfGood_3", "SelfGood_4",
                  "SelfNeut_1", "SelfNeut_2", "SelfNeut_3", "SelfNeut_4",
                  "SelfBad_1",  "SelfBad_2",  "SelfBad_3",  "SelfBad_4",
                  "GoodNeut_1", "GoodNeut_2", "GoodNeut_3", "GoodNeut_4", 
                  "GoodBad_1",  "GoodBad_2",  "GoodBad_3",  "GoodBad_4",
                  "NeutBad_1",  "NeutBad_2",  "NeutBad_3",  "NeutBad_4")

# Normalize the person distance by dividing the maximum value for each data point
df.perdist <- df.scales %>%
  dplyr::select(c(expID, subjID),perDistNames) %>%
  dplyr::mutate(sd_raw = matrixStats::rowSds(as.matrix(.[perDistNames]))) %>%
  dplyr::filter(sd_raw >=10) %>%                                # remove data with small variance
  dplyr::mutate(maxDist = pmax(!!!rlang::syms(perDistNames)))   # find the maximum value of the row

df.perdist[,3:31] <- df.perdist[,3:31]/df.perdist$maxDist       # dividing the maximum

# Get the mean value of each distance
df.perdist <- df.perdist %>%        
    dplyr::mutate(# sumRaw = rowMeans(.[3:31], na.rm = T),
                SelfGood = rowMeans(.[grep("SelfGood", names(.))], na.rm = T),
                SelfNeut = rowMeans(.[grep("SelfNeut", names(.))], na.rm = T),
                SelfBad  = rowMeans(.[grep("SelfBad", names(.))], na.rm = T),
                GoodNeut = rowMeans(.[grep("GoodNeut", names(.))], na.rm = T),
                GoodBad  = rowMeans(.[grep("GoodBad", names(.))], na.rm = T),
                NeutBad  = rowMeans(.[grep("NeutBad", names(.))], na.rm = T)) %>%
    dplyr::select(expID, subjID,
                SelfGood, SelfNeut, SelfBad, GoodNeut, GoodBad, NeutBad) %>%
  tidyr::drop_na()

# calculate the factor score for moral identity, moral self image, self-esteem, and personal distance.

df.scales <- df.scales %>%
  dplyr::mutate(morId_5_r = 0 - morId_5, # reverse the items that need to be reversed.
                SES3_r = 5 - SES3,
                SES5_r = 5 - SES5,
                SES9_r = 5 - SES9,
                SES10_r = 5 - SES10) %>%
  dplyr::mutate(SlfEst_sum = rowSums(.[SlfEstNames_r]),
                mrlIdInt_sum = rowSums(.[mrlIdIntNames_r]),
                mrlIdExt_sum = rowSums(.[mrlIdExtNames]),
                mrlSlfImg_sum = rowSums(.[mrlslfImgNames]))

df.scale.fs <- df.scales %>% dplyr::select(expID, subjID, SlfEst_sum, mrlIdInt_sum, mrlIdExt_sum, mrlSlfImg_sum)

# export data try to model individual predictor using exp1b's data
df1b.scale.fs <- df.scale.fs %>%
  dplyr::filter(expID == 'Exp1b') %>%
  dplyr::full_join(df1b.v, ., by =c ('Subject' = 'subjID' )) %>%
  dplyr::filter(!is.na(RESP)) %>%                       # exclude trials without response or with wrong keys
  dplyr::mutate(RT = RT/1000,
                stim = ifelse(Matchness == "Match", 1, 0), 
                response = ifelse((Matchness == "Match" & ACC ==1) | (Matchness == "Mismatch" & ACC ==0), 1, 0)) %>%
  dplyr::select(Subject, Matchness, Valence, stim, response, RT, SlfEst_sum, mrlIdInt_sum, mrlIdExt_sum, mrlSlfImg_sum) %>%   # select columns
  dplyr::rename(subj_idx = Subject, match = Matchness, val = Valence, rt = RT) %>%  # rename columns
  dplyr::filter(!is.na(mrlIdInt_sum))

write.csv(df1b.scale.fs, file = paste(curDir,'/HDDM/', 'df1bv.hddm_stim.reg.csv', sep = ''), row.names = F)

FS.m.id1 <- 'mrlIdInt =~ morId_1 + morId_2 + morId_5_r + morId_8 + morId_10 + morId_11 + morId_12 + morId_13 + morId_14
             
             mrlIdExt =~ morId_3 + morId_4 + morId_6 + morId_7 + morId_9 + morId_15 + morId_16 '

FS.m.id1.fit <- lavaan::cfa(FS.m.id1, data = df.scales, estimator = "MLR")

idx <- lavInspect(FS.m.id1.fit, "case.idx")
fscores <- lavPredict(FS.m.id1.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

FS.m.id2 <- ' morSlfImg =~ morSlfImg_1 + morSlfImg_2 + morSlfImg_3 + morSlfImg_4 + morSlfImg_5 + morSlfImg_6 + morSlfImg_7 + 
                          morSlfImg_8 + morSlfImg_9 '

FS.m.id2.fit <- lavaan::cfa(FS.m.id2, data = df.scales, estimator = "MLR")

idx <- lavInspect(FS.m.id2.fit, "case.idx")
fscores <- lavPredict(FS.m.id2.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

FS.m.id3 <- ' SlfEst =~ SES1 + SES2 + SES3_r + SES4 + SES5_r + SES6 + SES7 + SES8 + SES9_r + SES10_r '

FS.m.id3.fit <- lavaan::cfa(FS.m.id3, data = df.scales, estimator = "MLR")

# summary(FS.m.id3.fit, standardize = TRUE, fit.measures=TRUE)
# semPlot::semPaths(FS.m.id3.fit, "std", edge.label.cex = 0.5, curvePivot = TRUE, intercepts = FALSE)

idx <- lavInspect(FS.m.id3.fit, "case.idx")
fscores <- lavPredict(FS.m.id3.fit)
for (fs in colnames(fscores)) {
  df.scale.fs[idx, fs] <- fscores[ , fs]
}

df.scale.fs <- df.scale.fs %>%
  dplyr::left_join(., df.perdist)

```


```{r plot-person-dist, fig.cap="Self-rated personal distance", fig.width=8, warning=FALSE, eval=FALSE}
# Boxplot
p_dist_1 <- df.perdist %>% 
  tidyr::pivot_longer(., cols = SelfGood:NeutBad,
                      names_to = 'PerDist',
                      values_to = 'value') %>%
  dplyr::mutate(PerDist=factor(PerDist, levels = c('SelfNeut', 'SelfGood', 'GoodNeut', 'NeutBad', 'GoodBad', 'SelfBad'))) %>%
  ggplot2::ggplot(.,aes(x=PerDist, y=value)) +
  ggplot2::geom_boxplot() +
  ggplot2::geom_point(position = position_jitter(),size = 1, shape = 20, alpha = 0.15) + 
  scale_fill_brewer(palette = "Dark2") +
    theme_bw() +
    theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(3, "lines")) 

dist.cor <- df.perdist %>%
  dplyr::select(-c(subjID, expID)) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

p_dist_2 <- ggcorrplot::ggcorrplot(dist.cor$r, hc.order = TRUE, type = "lower",
     outline.col = "white", colors = c('red', 'white', 'blue'),
     lab = TRUE, p.mat = dist.cor$P) +
  #theme_bw() +
  scale_y_discrete(position='right') +
  theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          #axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          #axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(0, "lines")) 

# correlation bewteen self-reported measures
dist.cor2 <- df.scale.fs %>%
  dplyr::select(mrlIdInt:NeutBad) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

p_dist_3 <- ggcorrplot::ggcorrplot(dist.cor2$r, hc.order = TRUE, type = "lower",
     outline.col = "white", colors = c('red', 'white', 'blue'),  insig = "blank",
     lab = TRUE, p.mat = dist.cor2$P) +
  #theme_bw() +
  scale_y_discrete(position='right') +
  theme(panel.grid.major = element_blank(),
          panel.grid.minor = element_blank(),
          panel.background = element_blank(),
          panel.border = element_blank(),
          text=element_text(family='Times'),
          legend.title=element_blank(),
          legend.text = element_text(size =12),
          plot.title = element_text(lineheight=.8, face="bold", size = 16, margin=margin(0,0,20,0)),
          axis.text = element_text (size = 12, color = 'black'),
          axis.title = element_text (size = 12),
          axis.title.x = element_blank(),
          axis.title.y = element_blank(),
          axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
          #axis.line.x = element_line(color='black', size = 1),    # increase the size of font
          #axis.line.y = element_line(color='black', size = 1),    # increase the size of font
          strip.text = element_text (size = 12, color = 'black'), # size of text in strips, face = "bold"
          panel.spacing = unit(0, "lines")) 
# 
# corrplot(dist.cor$r, type = "upper", order = "hclust", 
#          tl.col = "black", tl.srt = 45,
#          p.mat = dist.cor$P, sig.level = 0.01, insig = "blank")

# col <- colorRampPalette(c( "red", "white", "blue"))(20)
# p_dist_2 <- heatmap(x = dist.cor$r, col = col, symm = TRUE)
# 
# corrplot(dist.cor$r, type="upper", order="hclust", col=col)
# legend(x="bottomright", legend=c("min", "ave", "max"), 
#      fill=colorRampPalette(c( "red", "white", "blue"))(20))
  
library(patchwork)
p_dist_1 + p_dist_2 + plot_annotation(tag_levels = 'A')  + plot_layout(nrow = 1, byrow = FALSE)

```

See Figure \@ref(fig:plot-person-dist).

## Correlation analyses
The reliability of questionnaires can be found in [@Liu_2020_JOPD]. We calculated the correlation between the data from behavioral task and the questionnaire data. First, we calculated the score for each scale based on their structure and factor loading, instead of sum score [@mcneish_thinking_2020]. Then, we used SEM to estimate the correlation because it can include measurement model and statistical model in a unified framework. 

To make sure that what we found were not false positive, we used two method to ensure the robustness of our analysis. first, we split the data into two half: the data with self and without, then, we used the conditional random forest to find the robust correlation in the exploratory data (with self reference) that can be replicated in the confirmatory data (without the self reference). The robust correlation were then analyzed using SEM


```{r correlation analysis, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
### failed attempt:
# We tried to first correlate the DDM parameters and the questionnaire separately for self-referential and other-referential, and then validation the correlation using data of experiment without self/other-referential. But the sample size for the correlation between questionnaires and behavioral results from experiment without identity are too small n = 16. Therefore, we give up this exploration-validation approach.

# Step 1: Get the parameter values
params.list <- list.files(here::here('HDDM'), pattern = '*_hddm_params.csv')

df_hddm_ls_1 <- params.list[c(1:4, 9:10)]
df_hddm_ls_2 <- params.list[c(5, 6, 11:13)]

for (indx in 1:6){
  if ((indx ==1) && exists('df_hddm_param_1')){   # if the variable already exist before the for loop start
    rm(df_hddm_param_1)
  }
  if (indx == 5 ){
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::filter(domain == "Morality") %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')  
    
  } else {
    hddm_params_tmp <- read.csv(here::here("HDDM", df_hddm_ls_1[indx]), header = TRUE, sep = ",",
                   stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
      dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val) %>%
      dplyr::select(Subject, Matchness, Valence, knode_name, mean) %>%
      tidyr::drop_na() %>%
      tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
      dplyr::rename(param = v1)  %>% dplyr::filter(Matchness=='Match') %>% dplyr::select(- c(v2, Matchness)) %>%
      tidyr::pivot_wider(., names_from = c('Valence', 'param'), values_from = 'mean')   # %>%
      #dplyr::mutate(ExpID = 'Exp1a')
  }
  if (exists('df_hddm_param_1')) {
    df_hddm_param_1 <- rbind(df_hddm_param_1, hddm_params_tmp) 
  } else {
    df_hddm_param_1 <- hddm_params_tmp
  }
}

for (indx in 1:5){
  if ((indx ==1) && exists('df_hddm_param_2')){   # in case the variable exist in the env.
    rm(df_hddm_param_2)
  }
  hddm_params_tmp <- read.csv(paste(here::here("HDDM", df_hddm_ls_2[indx])), header = TRUE, sep = ",",
                 stringsAsFactors=FALSE,na.strings=c("","NA")) %>%
    dplyr::rename(Subject = subj_idx, Matchness = match, Valence = val, Identity = id) %>%
    dplyr::select(Subject, Matchness, Identity, Valence, knode_name, mean) %>%
    tidyr::drop_na() %>%
    tidyr::separate(knode_name, into = paste('v', 1:2, sep= '')) %>%
    dplyr::rename(param = v1)  %>% 
    dplyr::filter(Matchness=='Match') %>% 
    dplyr::select(- c(v2, Matchness)) %>%
    tidyr::unite(conds, c(Valence, param)) %>%
    #tidyr::unite(conds, c(Identity, Valence, param)) %>%
    tidyr::pivot_wider(., names_from = c('conds'), values_from = 'mean')   # %>%
    #dplyr::mutate(ExpID = 'Exp1a')
  if (indx == 4 | indx == 5){
    hddm_params_tmp <- hddm_params_tmp %>%
      dplyr::mutate(Neutral_v = NA,
                    Neutral_a = NA,
                    #Other_Neutral_v = NA,
                    #Other_Neutral_a = NA,
                    #Other_Neutral_t = NA,
                    Neutral_t = NA) # %>%
      #dplyr::select(Subject, Identity, Bad_a, Good_a, Neutral_a, Bad_v, Good_v, Neutral_v, Bad_t, Good_t,
      #              Neutral_t)
  }
  
  if (exists('df_hddm_param_2')) {
    df_hddm_param_2 <- rbind(df_hddm_param_2, hddm_params_tmp) 
  } else {
    df_hddm_param_2 <- hddm_params_tmp
  }
}

df_hddm_param_1 <- df_hddm_param_1 %>%
  dplyr::mutate(Identity = NA) %>%
  dplyr::select(colnames(df_hddm_param_2))

df_hddm_param_all <- df_hddm_param_2 %>%
  dplyr::filter(Identity == "Self") %>%
  rbind(df_hddm_param_1, .)

# intersection between participant from behavioral task and scales and get the data
subj.common <- intersect(df.scale.fs$subjID, unique(df_hddm_param_all$Subject))  # 260

df.q_scores.v <- df.scale.fs %>% dplyr::filter(subjID %in% subj.common) %>%
  dplyr::select_if(~sum(!is.na(.)) > 0) # remove columns that only have NA.

# temp data for SEM
# tmp <- merge(df.scales.v, df_hddm_param_all, by.x = 'subjID', by.y = 'Subject')

## calculate correlation ----
df.corr <- merge(df.q_scores.v, df_hddm_param_all, by.x = 'subjID', by.y = 'Subject') %>%
  dplyr::select(-c(expID, Identity)) %>%
  dplyr::select(-contains('_sum')) # %>%
  
# library(corrr)
res.cor_all <-df.corr %>%
  dplyr::select(-c(subjID)) %>%
  as.matrix() %>%
  Hmisc::rcorr(., type = 'spearman')

#heatmap(x = res.cor_all$r, col = col, symm = TRUE)

p.mat <- res.cor_all$P %>%
  tidyr::replace_na(1)

# plat the corr matrix
#ggcorrplot::ggcorrplot(res.cor_all$r, hc.order = TRUE, p.mat = p.mat, insig = "blank", # type = "lower",
#                       outline.col = "black", colors = c('red', 'white', 'blue'), lab = T)

#res.cor_all <-df.corr %>%
#  dplyr::select(-c(subjID)) %>%
#  correlation::correlation(., method="spearman", p_adjust = "holm")

param1_names <- colnames(df.scale.fs)[7:length(df.scale.fs)]
param2_names <- colnames(df_hddm_param_all[3:11])

cor_pairs_all <- data.frame(matrix(ncol = 4, nrow = 0))
x <- c("Parameter1", "Parameter2", "r", 'p')
colnames(cor_pairs_all) <- x
i = 0
for (param1 in param1_names) {
  # print(param1)
  for (param2 in param2_names) {
    tmp_r <- res.cor_all$r[param1, param2]
    tmp_p <- res.cor_all$P[param1, param2]
    if (tmp_p <= 0.05) {
      i = i + 1
      cor_pairs_all[i, "Parameter1"] <- param1
      cor_pairs_all[i, "Parameter2"] <- param2
      cor_pairs_all[i, "r"] <- tmp_r
      cor_pairs_all[i, "p"] <- tmp_p
    }
  }
}

```

Instead of use the exploratory correlation analysis, we used a more principled way to explore the correlation between parameter of HDDM (*v*, *t*, and *a*) and scale scores and person distance. 

```{r get plots of correlation, echo=FALSE, results='hide', warning=FALSE, message=FALSE, eval=FALSE}
# Permutation
set.seed(12345)
permutation <- function(df) {
  v1 <- df[, 1] %>% base::sample(.)
  v2 <- df[, 2] %>% base::sample(.)
  tmp_cor <- cor(v1, v2, method = "pearson")
  tmp_cor
}

# plot for all
boot_plot_list <- list()
corr_plot_list <- list()
for (row_id in 1:nrow(cor_pairs_all)){
  
  # select variables
  var1 <- df.corr %>% dplyr::select(cor_pairs_all$Parameter1[row_id])
  var2 <- df.corr %>% dplyr::select(cor_pairs_all$Parameter2[row_id])
  var_tmp <- data.frame(var1, var2) %>%
    tidyr::drop_na()
  
  # boot
  boot_var <- var_tmp %>%
    bootES::bootES(., R = 5000, effect.type = 'r')
  
  cor_pairs_all$BootES_cor[row_id] <- boot_var$t0[1]
  cor_pairs_all$BootES_lb[row_id] <- boot_var$bounds[[1]]
  cor_pairs_all$BootES_ub[row_id] <- boot_var$bounds[[2]]
  
  # permutation
  per_cor <- rep(NA, 5000)
  for (i in 1:length(per_cor)){
    per_cor[i] <- permutation(var_tmp)
  }
  
  # plot scatter plot
  corr_plot_list[[row_id]] <- data.frame(var1, var2) %>%
    ggplot(., aes_string(x = cor_pairs_all$Parameter1[row_id], y = cor_pairs_all$Parameter2[row_id])) + 
    geom_point() + 
    geom_smooth(method=lm) +
    labs(title=paste(cor_pairs_all$Parameter1[row_id], '&', cor_pairs_all$Parameter2[row_id], sep = ' '), 
       x = cor_pairs_all$Parameter1[row_id], 
       y = cor_pairs_all$Parameter2[row_id]) +
    apatheme_s
  
  # plot permutation and boot 
  boot_cor <- boot_var$t %>%
    as.data.frame(.) %>%
    dplyr::arrange(V1) %>%
    dplyr::rename(corcoef = V1) %>%
    dplyr::mutate(Method = 'bootstrap')
    # dplyr::pull(V1)
  per_cor <- data.frame(per_cor) %>%
    dplyr::rename(corcoef = per_cor) %>%
    dplyr::mutate(Method = 'permutation')
  
  probs <- c(0.025, 0.975)
  quantiles <- quantile(per_cor$corcoef, prob=probs)
  
  # p_dist_df <- rbind(boot_cor, per_cor)
  
  xd <- data.frame(density(per_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'permutation')
  yd <- data.frame(density(boot_cor$corcoef)[c("x", "y")]) %>% dplyr::mutate(Method = 'bootstrap')
  zd <- rbind(xd, yd)
  
  label_r <- paste("r = ", round(cor_pairs_all$r[row_id], 3), sep = '')
  
  boot_plot_list[[row_id]] <- ggplot(zd, aes(x, y, group=Method, colour = Method)) + 
      geom_area(data = subset(xd, x > quantiles[1] & x < quantiles[2]), fill = "grey") + # plot the 95 % area of zero
      geom_line() + 
      geom_vline(xintercept = cor_pairs_all$r[row_id], colour = 'blue') +
      geom_vline(xintercept = quantiles[1], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = quantiles[2], colour = 'grey', linetype="dashed") + 
      geom_vline(xintercept = 0, colour = 'grey', linetype="dashed") + 
      # geom_text(aes(x = cor_pairs_all$r[row_id]*2, y = 6, label = label_r), colour = 'blue') +
      scale_color_grey() +
      apatheme_s
}

```
We didn't find the correlation between scale scores and the parameters of HDDM, but found weak correlation between personal distance and the parameter estimated from Good and neutral conditions. 

First, boundary separation (*a*) of moral good condition was correlated with both Self-Bad distance ($r = 0.198$, 95% CI [], $p = 0.0063$) and Neutral-Bad distance ($r = 0.1571$, 95% CI [], $p = 0.031$). At the same time, the non-decision time is negatively correlated with Self-Bad distance ($r = 0.169$, 95% CI [], $p = 0.0197$). See Figure \@ref(fig:plot-corr-1).

```{r plot-corr-1, fig.cap="Correlation between moral identity and boundary separation of good condition; moral self-image and drift rate of good condition", fig.width=8, warning=FALSE, eval=FALSE}
library(patchwork)
corr_plot_list[[3]] + corr_plot_list[[6]] + corr_plot_list[[5]]  + 
           boot_plot_list[[3]] + boot_plot_list[[6]] + boot_plot_list[[5]]+ plot_layout(ncol = 3)
```

Second, we found the boundary separation of neutral condition is positively correlated with the personal distance between self and good distance ($r = 0.189$, 95% CI [], $p = 0.036$), but negatively correlated with self-neutral distance($r = -0.183$, 95% CI [], $p = 0.042$). Also, the drift rate of the neutral condition is positively correlated with the Self-Bad distance ($r = 0.177$, 95% CI [], $p = 0.048$).a. See figure \@ref(fig:plot-corr-2)

```{r plot-corr-2, fig.cap="Correlation between personal distance and boundary separation of neutral condition", fig.width=8, warning=FALSE, eval=FALSE}
library(patchwork)
corr_plot_list[[1]] + corr_plot_list[[2]]  + corr_plot_list[[4]] + 
           boot_plot_list[[1]] + boot_plot_list[[2]] + boot_plot_list[[4]] + plot_layout(ncol = 3)
```

We also explored the correlation between behavioral data and questionnaire scores separately for experiments with and without self-referential, however, the sample size is very low for some conditions.

# Discussion

# References
```{r create_r-references, echo=FALSE,results='hide'}
#r_refs(file = "r-references.bib"))
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
